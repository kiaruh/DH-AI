{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"1.Practica_Guiada_Autoencoders_MidiFiles.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","id":"YEALZdFuQX1G","colab":{"base_uri":"https://localhost:8080/","height":446},"executionInfo":{"status":"ok","timestamp":1593707547903,"user_tz":180,"elapsed":42704,"user":{"displayName":"lionel chamorro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GglhTjMhHU8uZtGPAy83V2WmPGyzG8gT4cfIh79aQ=s64","userId":"01475641222516514519"}},"outputId":"7b1a8997-b8a7-4a16-f52a-4787a08f5085"},"source":["!pip install -U tqdm music21"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting tqdm\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/62/7663894f67ac5a41a0d8812d78d9d2a9404124051885af9d77dc526fb399/tqdm-4.47.0-py2.py3-none-any.whl (66kB)\n","\r\u001b[K     |█████                           | 10kB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 20kB 2.4MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 30kB 3.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 40kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 51kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 61kB 3.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 2.5MB/s \n","\u001b[?25hCollecting music21\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/96/87/19a01af679090c880ed0036f0c221dd7bc3a97f4bddf74e24bc22d1e66cf/music21-5.7.2.tar.gz (18.5MB)\n","\u001b[K     |████████████████████████████████| 18.5MB 161kB/s \n","\u001b[?25hBuilding wheels for collected packages: music21\n","  Building wheel for music21 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for music21: filename=music21-5.7.2-cp36-none-any.whl size=22024602 sha256=aa713d8e0096caf718696c662ebb87b9cfc270f2f1f7ddbe88579ad55414047c\n","  Stored in directory: /root/.cache/pip/wheels/6e/d0/05/1ef3daa9ae295073d807e468fcd820641965086424f1c633e3\n","Successfully built music21\n","Installing collected packages: tqdm, music21\n","  Found existing installation: tqdm 4.41.1\n","    Uninstalling tqdm-4.41.1:\n","      Successfully uninstalled tqdm-4.41.1\n","  Found existing installation: music21 5.5.0\n","    Uninstalling music21-5.5.0:\n","      Successfully uninstalled music21-5.5.0\n","Successfully installed music21-5.7.2 tqdm-4.47.0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["tqdm"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"eZ1qycruPuBk","colab":{"base_uri":"https://localhost:8080/","height":820},"executionInfo":{"status":"ok","timestamp":1593707635659,"user_tz":180,"elapsed":15156,"user":{"displayName":"lionel chamorro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GglhTjMhHU8uZtGPAy83V2WmPGyzG8gT4cfIh79aQ=s64","userId":"01475641222516514519"}},"outputId":"72e0fdc5-3418-45ea-b66e-b3493ffe45df"},"source":["!pip install -U google-api-python-client oauth2client PyDrive"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting google-api-python-client\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/e1/f465e0e8138cc76587d5b626c16c649b72f41a5cdbf414f8959221e03096/google_api_python_client-1.9.3-py3-none-any.whl (59kB)\n","\r\u001b[K     |█████▌                          | 10kB 21.6MB/s eta 0:00:01\r\u001b[K     |███████████                     | 20kB 2.2MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 30kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 40kB 3.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 51kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 2.2MB/s \n","\u001b[?25hRequirement already up-to-date: oauth2client in /usr/local/lib/python3.6/dist-packages (4.1.3)\n","Requirement already up-to-date: PyDrive in /usr/local/lib/python3.6/dist-packages (1.3.1)\n","Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client) (0.0.3)\n","Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client) (1.12.0)\n","Requirement already satisfied, skipping upgrade: google-auth>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client) (1.17.2)\n","Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client) (3.0.1)\n","Collecting google-api-core<2dev,>=1.18.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/76/bd5e3ebd571b9f688ae123a2bd84b2dc9f75e1214a83b8a759bc16e2fc35/google_api_core-1.21.0-py2.py3-none-any.whl (90kB)\n","\r\u001b[K     |███▋                            | 10kB 19.8MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 20kB 26.4MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 30kB 23.2MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 40kB 18.2MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 51kB 15.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 61kB 14.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 71kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 81kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 92kB 5.5MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client) (0.17.4)\n","Requirement already satisfied, skipping upgrade: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client) (0.4.8)\n","Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client) (0.2.8)\n","Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client) (4.6)\n","Requirement already satisfied, skipping upgrade: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (3.13)\n","Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.16.0->google-api-python-client) (4.1.0)\n","Requirement already satisfied, skipping upgrade: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.16.0->google-api-python-client) (47.3.1)\n","Requirement already satisfied, skipping upgrade: pytz in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.18.0->google-api-python-client) (2018.9)\n","Collecting protobuf>=3.12.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/05/9867ef8eafd12265267bee138fa2c46ebf34a276ea4cbe184cba4c606e8b/protobuf-3.12.2-cp36-cp36m-manylinux1_x86_64.whl (1.3MB)\n","\u001b[K     |████████████████████████████████| 1.3MB 13.2MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.18.0->google-api-python-client) (2.23.0)\n","Requirement already satisfied, skipping upgrade: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.18.0->google-api-python-client) (1.52.0)\n","Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.18.0->google-api-python-client) (3.0.4)\n","Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.18.0->google-api-python-client) (2020.6.20)\n","Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.18.0->google-api-python-client) (2.9)\n","Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.18.0->google-api-python-client) (1.24.3)\n","\u001b[31mERROR: google-api-core 1.21.0 has requirement google-auth<2.0dev,>=1.18.0, but you'll have google-auth 1.17.2 which is incompatible.\u001b[0m\n","Installing collected packages: protobuf, google-api-core, google-api-python-client\n","  Found existing installation: protobuf 3.10.0\n","    Uninstalling protobuf-3.10.0:\n","      Successfully uninstalled protobuf-3.10.0\n","  Found existing installation: google-api-core 1.16.0\n","    Uninstalling google-api-core-1.16.0:\n","      Successfully uninstalled google-api-core-1.16.0\n","  Found existing installation: google-api-python-client 1.7.12\n","    Uninstalling google-api-python-client-1.7.12:\n","      Successfully uninstalled google-api-python-client-1.7.12\n","Successfully installed google-api-core-1.21.0 google-api-python-client-1.9.3 protobuf-3.12.2\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["apiclient","google","googleapiclient"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"NgIghEv5U2aG","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593707607495,"user_tz":180,"elapsed":3547,"user":{"displayName":"lionel chamorro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GglhTjMhHU8uZtGPAy83V2WmPGyzG8gT4cfIh79aQ=s64","userId":"01475641222516514519"}},"outputId":"376db186-6399-4eb6-e9f3-59bf88689588"},"source":["import os\n","from glob import glob\n","from tqdm import tqdm\n","from functools import reduce\n","from music21 import converter, instrument, note, chord, stream\n","import matplotlib.pyplot as plt\n","from IPython.display import clear_output\n","import numpy as np\n","import keras\n","import tensorflow as tf\n","from keras.utils.np_utils import to_categorical\n","from keras.utils import normalize\n","from keras.models import Sequential, Model, model_from_json\n","from keras.layers import Input, Dense, Dropout, Activation, LSTM, Embedding\n","from keras.layers import Conv1D, GlobalAveragePooling1D, MaxPooling1D, RepeatVector, UpSampling1D\n","from keras import backend as K\n","from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n","from sklearn.model_selection import train_test_split"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"j-y0GGoXPrTF"},"source":["###  Bajada de archivos de Gdrive\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"U75qK_j0PuyX","colab":{"base_uri":"https://localhost:8080/","height":102},"executionInfo":{"status":"ok","timestamp":1593707663925,"user_tz":180,"elapsed":28259,"user":{"displayName":"lionel chamorro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GglhTjMhHU8uZtGPAy83V2WmPGyzG8gT4cfIh79aQ=s64","userId":"01475641222516514519"}},"outputId":"b6f6e040-9aed-4a60-ac68-4d94dba56c55"},"source":["import os\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","# 1. Authenticate and create the PyDrive client.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","\n","def download_from_drive(local_fn, id):\n","  print('Downloading: %s, id: %s' % (local_fn, id))\n","  downloaded = drive.CreateFile({'id': id})\n","  downloaded.GetContentFile(local_fn)\n","\n","fns = [\n","    ('LSTMSinRegularizanTrTe.h5', '1dglMb7yK-tMocu5ufoyz3ofT5IeLzd5L'), \n","    ('LSTMSinRegularizanTrTe.json', '1cI3-BiytVBsBAVISKwYdgCe_Zd6ArY7D'), \n","    ('LSTMAutoencoder.h5', '1M1YIRGvhtDPWGKzwjldxTD_yrCWsaeWd'), \n","    ('LSTMAutoencoder.json', '1SIZWIIim6wpJ4GW0Kqq2aVFajRVr0zFi'), \n","    ('bach.tar.gz', '179tgDp-U3oPf0DuCIDuA59-L9nfhqBJN'), \n","]\n","\n","for local_fn, id in fns:\n","  download_from_drive(local_fn, id)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading: LSTMSinRegularizanTrTe.h5, id: 1dglMb7yK-tMocu5ufoyz3ofT5IeLzd5L\n","Downloading: LSTMSinRegularizanTrTe.json, id: 1cI3-BiytVBsBAVISKwYdgCe_Zd6ArY7D\n","Downloading: LSTMAutoencoder.h5, id: 1M1YIRGvhtDPWGKzwjldxTD_yrCWsaeWd\n","Downloading: LSTMAutoencoder.json, id: 1SIZWIIim6wpJ4GW0Kqq2aVFajRVr0zFi\n","Downloading: bach.tar.gz, id: 179tgDp-U3oPf0DuCIDuA59-L9nfhqBJN\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"yxqsCNh1Sg_X","colab":{}},"source":["!tar -xzf bach.tar.gz"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Sdz5vJHoU2aV"},"source":["## Práctica Guiada - Autoencoders con midi files\n","\n","### Introducción: Archivos Midi\n","\n","En esta práctica vamos a utilizar autoencoders para codificar y decodificar archivos de audio de tipo midi, Musical Instrument Digital Interface.\n","MIDI es un protocolo de representación de música, que cuenta con una importante difusión.\n","\n","A diferencia de los archivos de audio que venimos trabajando en el resto de este módulo, como los .wav ó .mp3, los archivos midi <strong> no contienen una señal de audio sino las instrucciones necesarias para generarlo </strong>. \n","\n","En este sentido, el contenido de un archivo midi puede entenderse como una secuencia de instrucciones que opera sobre distintos canales: uno por cada instrumento que deberá generar la música. En total, los archivos midi pueden mandar instrucciones por un máximo de 16 canales, permitiendo entonces, 16 instrumentos simultáneamente.\n","\n","### Estructura de un archivo Midi\n","\n","Los archivos Midi almacenan la secuencia de instrucciones en un formate de nota/time_delta. Es decir, se guarda, para cada instrumento, las notas a tocar y el tiempo hasta la siguiente instrucción.\n","<br>\n","<img src='https://image.ibb.co/c1Z8E7/Selecci_n_126.png'></img>\n","\n","La librería de Python music21 permite parsear archivos de tipo midi y trabajar con objetos que representan las instrucciones de forma más clara, como por ejemplo, nota, acorde e instrumento. Cuando un conjunto de notas se debe reproducir simultáneamente, music21 lo parsea como un acorde. Cada nota y acorde tiene asociado un offset que indica en qué momento de la reproducción del audio se lo debe tocar. \n","\n","## Preprocesamiento de datos\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"pdimPocMU2aY"},"source":["Escribimos una función que reciba lea un archivo midi y almacene en una lista la secuencia de notas y acordes. Por simplicidad, en esta práctica vamos a trabajar exclusivamente con música de piano, pero se podría trabajar con más instrumentos utilizando varios canales. \n","\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"s5x5zvufU2aa","colab":{}},"source":["def get_notes(audio_file):\n","    midi = converter.parse(audio_file)\n","    instrument_partition = instrument.partitionByInstrument(midi)\n","    audio_features = instrument_partition.parts[0].recurse()\n","    \n","    def get_note_chord(audio_feature):\n","        if isinstance(audio_feature, note.Note):\n","            return str(audio_feature.pitch)\n","        elif isinstance(audio_feature, chord.Chord):\n","            return '.'.join(map(lambda x: str(x), audio_feature.normalOrder))\n","    \n","    return list(filter(lambda x: x!= None, map(get_note_chord, audio_features)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ddaafNfdU2ak"},"source":["Leamos ahora los archivos que componen nuestro input:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"8o8FuebcU2an","colab":{}},"source":["# Trabajamos con los primeros 400 archivos para aligerar el procesamiento\n","nmidis = 400\n","audio_files = sorted(glob(\"./bach/*.mid\"), key=os.path.getsize)[0:nmidis]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"pWiryouaU2aw","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593707804888,"user_tz":180,"elapsed":745,"user":{"displayName":"lionel chamorro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GglhTjMhHU8uZtGPAy83V2WmPGyzG8gT4cfIh79aQ=s64","userId":"01475641222516514519"}},"outputId":"ffb0a05a-52de-4877-c864-501fea962d4c"},"source":["len(audio_files)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["400"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"hVS6ZPddU2a4"},"source":["Con estos audios y la función anterior, creamos una lista de listas que contenga la secuencia de instrucciones para cada audio:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"YVZyf5YdU2a6","colab":{"base_uri":"https://localhost:8080/","height":170},"executionInfo":{"status":"ok","timestamp":1593708007248,"user_tz":180,"elapsed":194555,"user":{"displayName":"lionel chamorro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GglhTjMhHU8uZtGPAy83V2WmPGyzG8gT4cfIh79aQ=s64","userId":"01475641222516514519"}},"outputId":"f0502141-ccec-4457-e1b5-873b1a7f7b00"},"source":["midis_notes_chords_by_file = []\n","\n","for file in audio_files:\n","    try:\n","        notes_file = get_notes(file)\n","        midis_notes_chords_by_file.append(notes_file)\n","    except Exception as err:\n","        print(file, err)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["./bach/458b2d957a32475619d157902a430866.mid 'NoneType' object has no attribute 'parts'\n","./bach/b92f0db2ea8e70515dddd1d73fbcfeb1.mid 'NoneType' object has no attribute 'parts'\n","./bach/60fc529f381b1ce1aaccc313215f9fb4.mid 'NoneType' object has no attribute 'parts'\n","./bach/19cf29a73f93f11c14972f647b3bdc4e.mid 'NoneType' object has no attribute 'parts'\n","./bach/24e3ce35ec2f4fcf2cd1adc296799810.mid 'NoneType' object has no attribute 'parts'\n","./bach/bc66a983c37d0dce783d90fa183ee739.mid 'NoneType' object has no attribute 'parts'\n","./bach/0f2a3840813cf4fe6e22dcf73666e12a.mid 'NoneType' object has no attribute 'parts'\n","./bach/327852b1e95de5032bb1db6f7738045f.mid 'NoneType' object has no attribute 'parts'\n","./bach/11c8c6bd558ce7512d454e9a395f1fb7.mid 'NoneType' object has no attribute 'parts'\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"8uT7WURGT82v","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593708007249,"user_tz":180,"elapsed":191627,"user":{"displayName":"lionel chamorro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GglhTjMhHU8uZtGPAy83V2WmPGyzG8gT4cfIh79aQ=s64","userId":"01475641222516514519"}},"outputId":"bf90da4f-709a-4c13-a48b-18827ef9eac3"},"source":["len(midis_notes_chords_by_file)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["391"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"u2wziwYMU2bC"},"source":["Para simplificar el trabajo de los autoencoders (y de paso simplificar el conjunto de entrenamiento), vamos a dividir cada audio en chunks de un máximo de 10 instrucciones cada uno:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ad-StKuzU2bG","colab":{}},"source":["timesteps = 10"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"tsxWuiLOU2bP","colab":{}},"source":["def get_chunks(file_notes):\n","    new_chunks = []\n","    num_chunks = len(file_notes) // timesteps\n","    for n in range(0,num_chunks):\n","        new_chunks.append(file_notes[n*timesteps:n*timesteps + timesteps])\n","    return new_chunks"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"7HmDjvcgU2be","colab":{}},"source":["all_chunks = []"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"nrpnv7UoU2bs","colab":{}},"source":["for file in midis_notes_chords_by_file:\n","    all_chunks = all_chunks + get_chunks(file)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ptBKzk6G7nHM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593708007250,"user_tz":180,"elapsed":187332,"user":{"displayName":"lionel chamorro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GglhTjMhHU8uZtGPAy83V2WmPGyzG8gT4cfIh79aQ=s64","userId":"01475641222516514519"}},"outputId":"261ef849-57f4-4e0f-9842-20bff4cc7a14"},"source":["len(all_chunks)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["18335"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"WqUdjKKhW3i6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593708007250,"user_tz":180,"elapsed":186448,"user":{"displayName":"lionel chamorro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GglhTjMhHU8uZtGPAy83V2WmPGyzG8gT4cfIh79aQ=s64","userId":"01475641222516514519"}},"outputId":"240c998f-a21b-40a6-fa1d-cc63a0653911"},"source":["all_chunks[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['C5', 'B4', 'C5', 'G4', 'G#4', 'F4', 'B4', 'C5', 'D5', 'G4']"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"DL78Do5OU2b2"},"source":["Una vez que definimos que nuestros audios van a ser unidades de 10 instrucciones, tendremos que construir los arrays necesarios para alimentar a un autoencoder.\n","\n","La cantidad 10 representa los pasos de nuestra secuencia, así que vamos a conservarla en el eje Y.\n","\n","Nuestros samples están dados por todos los chunks almacenados en la lista all_chunks.\n","La listas de all_chunks contienen descripciones de los datos. Para alimentar a la red neuronal vamos a transformar estas representaciones a números.\n","Para esto vamos a utilizar la clase LabelEncoder de sklearn."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"RTU_yBPwU2b6","colab":{}},"source":["# Pasamos a numpy array\n","array_input = np.array(all_chunks)\n","\n","# Instanciamos el LabelEncoder\n","le = LabelEncoder()\n","\n","# El LabelEncoder \"aprende\" todas las clases que existen. \n","# El método fit de LE exige un input unidimensional, por eso hacemos reshape.\n","le.fit(array_input.reshape(len(all_chunks)*timesteps))\n","\n","# Usamos el diccionario aprendido por LabelEncoder para transformar un array de dos dimensiones\n","array_input = le.transform(array_input.reshape(len(all_chunks)*timesteps))\n","\n","# Normalizamos el input para una NN\n","aray_input = array_input/len(le.classes_)\n","\n","# Agregamos la dimensión de canal (un único instrumento)\n","array_input = array_input.reshape(len(all_chunks),timesteps,1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5sNExXDwgC0T","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593708007251,"user_tz":180,"elapsed":182073,"user":{"displayName":"lionel chamorro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GglhTjMhHU8uZtGPAy83V2WmPGyzG8gT4cfIh79aQ=s64","userId":"01475641222516514519"}},"outputId":"8afaf4af-c038-4d55-ae4a-f73f878895fd"},"source":["# Verificamos la shape resultante\n","array_input.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(18335, 10, 1)"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"QPnx6GvcgQLE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":935},"executionInfo":{"status":"ok","timestamp":1593708007252,"user_tz":180,"elapsed":180777,"user":{"displayName":"lionel chamorro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GglhTjMhHU8uZtGPAy83V2WmPGyzG8gT4cfIh79aQ=s64","userId":"01475641222516514519"}},"outputId":"572b7647-a4cb-443e-fbb6-2af0661d6b10"},"source":["# Vemos algunos ejemplos\n","array_input[:5]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[[216],\n","        [205],\n","        [216],\n","        [253],\n","        [247],\n","        [241],\n","        [205],\n","        [216],\n","        [222],\n","        [253]],\n","\n","       [[216],\n","        [205],\n","        [216],\n","        [222],\n","        [241],\n","        [253],\n","        [247],\n","        [253],\n","        [241],\n","        [226]],\n","\n","       [[253],\n","        [193],\n","        [205],\n","        [222],\n","        [216],\n","        [216],\n","        [232],\n","        [222],\n","        [222],\n","        [254]],\n","\n","       [[237],\n","        [254],\n","        [222],\n","        [205],\n","        [253],\n","        [193],\n","        [205],\n","        [216],\n","        [222],\n","        [232]],\n","\n","       [[222],\n","        [216],\n","        [205],\n","        [193],\n","        [205],\n","        [253],\n","        [236],\n","        [193],\n","        [221],\n","        [236]]])"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"PL3rr12pU2cN"},"source":["## Ajustamos el autoencoder\n","\n","En primer lugar vamos a ajustar un autoencoder básico. Vamos a trabajar con un encoder y un decoder básicos de 3 capas convolucionales. Utilizamos convoluciones 1D para captar las propiedades de las secuencias de instrucciones. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"6wUtbYdAU2cP","colab":{}},"source":["timesteps = 10"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"aym7SbsIU2ce","colab":{}},"source":["from keras.layers import Input, Dense, MaxPooling1D, UpSampling1D\n","from keras.models import Model\n","from keras import backend as K\n","\n","input_aud = Input(shape=(timesteps, 1))\n","\n","x = Conv1D(32, 2, activation='relu', padding='same')(input_aud)\n","x = MaxPooling1D(2, padding='same')(x)\n","x = Conv1D(16, 2, activation='relu', padding='same')(x)\n","x = MaxPooling1D(2, padding='same')(x)\n","x = Conv1D(16, 2, activation='relu', padding='same')(x)\n","encoded = MaxPooling1D(2, padding='same')(x)\n","\n","# En este punto, la representacion es (4, 4, 8), o sea, 128-dimensional\n","\n","x = Conv1D(16, 3, activation='relu', padding='same')(encoded)\n","x = UpSampling1D(2)(x)\n","x = Conv1D(16, 3, activation='relu', padding='same')(x)\n","x = UpSampling1D(2)(x)\n","x = Conv1D(32, 4, activation='relu')(x)\n","x = UpSampling1D(2)(x)\n","\n","decoded = Conv1D(1, 2, activation='sigmoid', padding='same')(x)\n","\n","autoencoder = Model(input_aud, decoded, name='Autoencoder')\n","autoencoder.compile(optimizer='Adam', loss='binary_crossentropy')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jcQYaiYi7nHk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":642},"executionInfo":{"status":"ok","timestamp":1593695189652,"user_tz":180,"elapsed":30773,"user":{"displayName":"Julián Ansaldo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhUb7AsWoOmdCsmzYzXTDr9Sws-IR4J0wcrp266tQ=s64","userId":"10643095115217147090"}},"outputId":"0e966435-d255-41ff-c1ab-913986ea7bef"},"source":["autoencoder.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"Autoencoder\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         (None, 10, 1)             0         \n","_________________________________________________________________\n","conv1d_1 (Conv1D)            (None, 10, 32)            96        \n","_________________________________________________________________\n","max_pooling1d_1 (MaxPooling1 (None, 5, 32)             0         \n","_________________________________________________________________\n","conv1d_2 (Conv1D)            (None, 5, 16)             1040      \n","_________________________________________________________________\n","max_pooling1d_2 (MaxPooling1 (None, 3, 16)             0         \n","_________________________________________________________________\n","conv1d_3 (Conv1D)            (None, 3, 16)             528       \n","_________________________________________________________________\n","max_pooling1d_3 (MaxPooling1 (None, 2, 16)             0         \n","_________________________________________________________________\n","conv1d_4 (Conv1D)            (None, 2, 16)             784       \n","_________________________________________________________________\n","up_sampling1d_1 (UpSampling1 (None, 4, 16)             0         \n","_________________________________________________________________\n","conv1d_5 (Conv1D)            (None, 4, 16)             784       \n","_________________________________________________________________\n","up_sampling1d_2 (UpSampling1 (None, 8, 16)             0         \n","_________________________________________________________________\n","conv1d_6 (Conv1D)            (None, 5, 32)             2080      \n","_________________________________________________________________\n","up_sampling1d_3 (UpSampling1 (None, 10, 32)            0         \n","_________________________________________________________________\n","conv1d_7 (Conv1D)            (None, 10, 1)             65        \n","=================================================================\n","Total params: 5,377\n","Trainable params: 5,377\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"iP03mE8MU2dE","colab":{}},"source":["x_train, x_test, y_train, y_test = train_test_split(array_input, array_input, random_state=42, test_size = 0.2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VdGZduoe7nHv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593708127487,"user_tz":180,"elapsed":922,"user":{"displayName":"lionel chamorro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GglhTjMhHU8uZtGPAy83V2WmPGyzG8gT4cfIh79aQ=s64","userId":"01475641222516514519"}},"outputId":"ce0c9b8a-5255-478e-aef8-5bd1e803bbde"},"source":["x_train.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(14668, 10, 1)"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"RbcIiM4T7nH0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593695403343,"user_tz":180,"elapsed":242991,"user":{"displayName":"Julián Ansaldo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhUb7AsWoOmdCsmzYzXTDr9Sws-IR4J0wcrp266tQ=s64","userId":"10643095115217147090"}},"outputId":"971fa666-9f82-43f3-ecc1-b8483ca5f2e1"},"source":["autoencoder.fit(x_train, x_train,\n","                epochs=300,\n","                batch_size=128,\n","                shuffle=True,\n","                validation_data=(x_test, x_test),)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train on 14668 samples, validate on 3667 samples\n","Epoch 1/300\n","14668/14668 [==============================] - 2s 168us/step - loss: -107326960.7371 - val_loss: -1145259291.7153\n","Epoch 2/300\n","14668/14668 [==============================] - 1s 43us/step - loss: -136545470041.2195 - val_loss: -723218975151.7164\n","Epoch 3/300\n","14668/14668 [==============================] - 1s 47us/step - loss: -7897337254550.3740 - val_loss: -26813978024949.6680\n","Epoch 4/300\n","14668/14668 [==============================] - 1s 48us/step - loss: -120204045951496.5312 - val_loss: -305591180094481.5625\n","Epoch 5/300\n","14668/14668 [==============================] - 1s 56us/step - loss: -879252413804904.7500 - val_loss: -1842638216126658.2500\n","Epoch 6/300\n","14668/14668 [==============================] - 1s 50us/step - loss: -4113047722355568.5000 - val_loss: -7542744100779886.0000\n","Epoch 7/300\n","14668/14668 [==============================] - 1s 43us/step - loss: -14326313000616164.0000 - val_loss: -23861732268123016.0000\n","Epoch 8/300\n","14668/14668 [==============================] - 1s 42us/step - loss: -40587010609514160.0000 - val_loss: -62882421136280344.0000\n","Epoch 9/300\n","14668/14668 [==============================] - 1s 44us/step - loss: -98725809271899936.0000 - val_loss: -144711017989193824.0000\n","Epoch 10/300\n","14668/14668 [==============================] - 1s 43us/step - loss: -213839982060686752.0000 - val_loss: -299878525118316736.0000\n","Epoch 11/300\n","14668/14668 [==============================] - 1s 43us/step - loss: -422759823878183936.0000 - val_loss: -572025454101497216.0000\n","Epoch 12/300\n","14668/14668 [==============================] - 1s 47us/step - loss: -776628132794207744.0000 - val_loss: -1020397514788765312.0000\n","Epoch 13/300\n","14668/14668 [==============================] - 1s 43us/step - loss: -1343672083973374464.0000 - val_loss: -1722514868859218688.0000\n","Epoch 14/300\n","14668/14668 [==============================] - 1s 53us/step - loss: -2211094136315140608.0000 - val_loss: -2776405356547002880.0000\n","Epoch 15/300\n","14668/14668 [==============================] - 1s 53us/step - loss: -3487601114437858816.0000 - val_loss: -4301901577917211136.0000\n","Epoch 16/300\n","14668/14668 [==============================] - 1s 53us/step - loss: -5306481267856626688.0000 - val_loss: -6444244008942540800.0000\n","Epoch 17/300\n","14668/14668 [==============================] - 1s 43us/step - loss: -7826084796487545856.0000 - val_loss: -9375677867842162688.0000\n","Epoch 18/300\n","14668/14668 [==============================] - 1s 47us/step - loss: -11232746844253726720.0000 - val_loss: -13298145607034099712.0000\n","Epoch 19/300\n","14668/14668 [==============================] - 1s 44us/step - loss: -15743091490320236544.0000 - val_loss: -18442446146022719488.0000\n","Epoch 20/300\n","14668/14668 [==============================] - 1s 44us/step - loss: -21602560774194270208.0000 - val_loss: -25068903710438641664.0000\n","Epoch 21/300\n","14668/14668 [==============================] - 1s 48us/step - loss: -29090878835996647424.0000 - val_loss: -33479719078971924480.0000\n","Epoch 22/300\n","14668/14668 [==============================] - 1s 50us/step - loss: -38519251538603982848.0000 - val_loss: -43995851744522838016.0000\n","Epoch 23/300\n","14668/14668 [==============================] - 1s 43us/step - loss: -50237947057612636160.0000 - val_loss: -56991460659021570048.0000\n","Epoch 24/300\n","14668/14668 [==============================] - 1s 46us/step - loss: -64635492692142432256.0000 - val_loss: -72866320264400912384.0000\n","Epoch 25/300\n","14668/14668 [==============================] - 1s 44us/step - loss: -82137018163772915712.0000 - val_loss: -92079208308860600320.0000\n","Epoch 26/300\n","14668/14668 [==============================] - 1s 43us/step - loss: -103206260256217694208.0000 - val_loss: -115102600045971849216.0000\n","Epoch 27/300\n","14668/14668 [==============================] - 1s 47us/step - loss: -128359233040094347264.0000 - val_loss: -142467396864229556224.0000\n","Epoch 28/300\n","14668/14668 [==============================] - 1s 45us/step - loss: -158133078439253639168.0000 - val_loss: -174756025656127717376.0000\n","Epoch 29/300\n","14668/14668 [==============================] - 1s 43us/step - loss: -193123661622280159232.0000 - val_loss: -212573086117818171392.0000\n","Epoch 30/300\n","14668/14668 [==============================] - 1s 46us/step - loss: -233972248773902303232.0000 - val_loss: -256565405085605527552.0000\n","Epoch 31/300\n","14668/14668 [==============================] - 1s 44us/step - loss: -281363757778289033216.0000 - val_loss: -307474743262648664064.0000\n","Epoch 32/300\n","14668/14668 [==============================] - 1s 45us/step - loss: -336048367086881931264.0000 - val_loss: -366058508471797678080.0000\n","Epoch 33/300\n","14668/14668 [==============================] - 1s 43us/step - loss: -398806326841516752896.0000 - val_loss: -433094892180529086464.0000\n","Epoch 34/300\n","14668/14668 [==============================] - 1s 42us/step - loss: -470471358410430676992.0000 - val_loss: -509481679436832899072.0000\n","Epoch 35/300\n","14668/14668 [==============================] - 1s 44us/step - loss: -551934905815632510976.0000 - val_loss: -596158706955551113216.0000\n","Epoch 36/300\n","14668/14668 [==============================] - 1s 48us/step - loss: -644147075722693836800.0000 - val_loss: -694037502702544093184.0000\n","Epoch 37/300\n","14668/14668 [==============================] - 1s 43us/step - loss: -748115746471125975040.0000 - val_loss: -804221307062250242048.0000\n","Epoch 38/300\n","14668/14668 [==============================] - 1s 44us/step - loss: -864911201588487520256.0000 - val_loss: -927756738872110612480.0000\n","Epoch 39/300\n","14668/14668 [==============================] - 1s 55us/step - loss: -995646558528985235456.0000 - val_loss: -1065792711420014886912.0000\n","Epoch 40/300\n","14668/14668 [==============================] - 1s 53us/step - loss: -1141497352878346862592.0000 - val_loss: -1219599634552840781824.0000\n","Epoch 41/300\n","14668/14668 [==============================] - 1s 44us/step - loss: -1303743955872897564672.0000 - val_loss: -1390374991132658761728.0000\n","Epoch 42/300\n","14668/14668 [==============================] - 1s 50us/step - loss: -1483672925364772143104.0000 - val_loss: -1579563074111372787712.0000\n","Epoch 43/300\n","14668/14668 [==============================] - 1s 52us/step - loss: -1682669612298205921280.0000 - val_loss: -1788461329805666942976.0000\n","Epoch 44/300\n","14668/14668 [==============================] - 1s 58us/step - loss: -1902216281401591595008.0000 - val_loss: -2018754347034379550720.0000\n","Epoch 45/300\n","14668/14668 [==============================] - 1s 56us/step - loss: -2143811072914396282880.0000 - val_loss: -2271859390377675980800.0000\n","Epoch 46/300\n","14668/14668 [==============================] - 1s 60us/step - loss: -2409045873902152581120.0000 - val_loss: -2549314784024530518016.0000\n","Epoch 47/300\n","14668/14668 [==============================] - 1s 48us/step - loss: -2699672969412396711936.0000 - val_loss: -2852986559693399261184.0000\n","Epoch 48/300\n","14668/14668 [==============================] - 1s 44us/step - loss: -3017420579380022738944.0000 - val_loss: -3184796748154047823872.0000\n","Epoch 49/300\n","14668/14668 [==============================] - 1s 45us/step - loss: -3364083016666583138304.0000 - val_loss: -3546440771826421858304.0000\n","Epoch 50/300\n","14668/14668 [==============================] - 1s 46us/step - loss: -3741601788275692929024.0000 - val_loss: -3939948653880038916096.0000\n","Epoch 51/300\n","14668/14668 [==============================] - 1s 52us/step - loss: -4151959822936513183744.0000 - val_loss: -4367069388860854632448.0000\n","Epoch 52/300\n","14668/14668 [==============================] - 1s 57us/step - loss: -4597357856741620449280.0000 - val_loss: -4830422912308441251840.0000\n","Epoch 53/300\n","14668/14668 [==============================] - 1s 57us/step - loss: -5079855083784946843648.0000 - val_loss: -5332041173120217776128.0000\n","Epoch 54/300\n","14668/14668 [==============================] - 1s 47us/step - loss: -5601754550978357493760.0000 - val_loss: -5874033130119943421952.0000\n","Epoch 55/300\n","14668/14668 [==============================] - 1s 45us/step - loss: -6165416592031124291584.0000 - val_loss: -6459256882830942142464.0000\n","Epoch 56/300\n","14668/14668 [==============================] - 1s 45us/step - loss: -6773382854597146574848.0000 - val_loss: -7089549955781677285376.0000\n","Epoch 57/300\n","14668/14668 [==============================] - 1s 44us/step - loss: -7428114528853637988352.0000 - val_loss: -7768429820400242786304.0000\n","Epoch 58/300\n","14668/14668 [==============================] - 1s 47us/step - loss: -8130564259068247015424.0000 - val_loss: -8483236535900133392384.0000\n","Epoch 59/300\n","14668/14668 [==============================] - 1s 46us/step - loss: -8843273949761431928832.0000 - val_loss: -9201981266554160939008.0000\n","Epoch 60/300\n","14668/14668 [==============================] - 1s 60us/step - loss: -9556628994030494023680.0000 - val_loss: -9905350321522402656256.0000\n","Epoch 61/300\n","14668/14668 [==============================] - 1s 47us/step - loss: -10276149083469428817920.0000 - val_loss: -10641633493771054219264.0000\n","Epoch 62/300\n","14668/14668 [==============================] - 1s 44us/step - loss: -11030346840913404231680.0000 - val_loss: -11413170665822055563264.0000\n","Epoch 63/300\n","14668/14668 [==============================] - 1s 45us/step - loss: -11801842005875298926592.0000 - val_loss: -12148027723263288279040.0000\n","Epoch 64/300\n","14668/14668 [==============================] - 1s 45us/step - loss: -12500650664217458769920.0000 - val_loss: -12840506797386348101632.0000\n","Epoch 65/300\n","14668/14668 [==============================] - 1s 45us/step - loss: -13203620269119189811200.0000 - val_loss: -13552992907140081385472.0000\n","Epoch 66/300\n","14668/14668 [==============================] - 1s 44us/step - loss: -13926773661199251800064.0000 - val_loss: -14285999335462196477952.0000\n","Epoch 67/300\n","14668/14668 [==============================] - 1s 47us/step - loss: -14671500474511502868480.0000 - val_loss: -15041363716799937380352.0000\n","Epoch 68/300\n","14668/14668 [==============================] - 1s 45us/step - loss: -15438984873899171250176.0000 - val_loss: -15819840347903354732544.0000\n","Epoch 69/300\n","14668/14668 [==============================] - 1s 46us/step - loss: -16230420409058641051648.0000 - val_loss: -16623329495124818264064.0000\n","Epoch 70/300\n","14668/14668 [==============================] - 1s 59us/step - loss: -17046897288839010713600.0000 - val_loss: -17451755799622461685760.0000\n","Epoch 71/300\n","14668/14668 [==============================] - 1s 60us/step - loss: -17889459822094641528832.0000 - val_loss: -18307284435079064977408.0000\n","Epoch 72/300\n","14668/14668 [==============================] - 1s 59us/step - loss: -18759123968459769118720.0000 - val_loss: -19190122081654048555008.0000\n","Epoch 73/300\n","14668/14668 [==============================] - 1s 50us/step - loss: -19656784927050969382912.0000 - val_loss: -20101017638102844309504.0000\n","Epoch 74/300\n","14668/14668 [==============================] - 1s 44us/step - loss: -20583500381197642498048.0000 - val_loss: -21041785150241087946752.0000\n","Epoch 75/300\n","14668/14668 [==============================] - 1s 42us/step - loss: -21540040463937097957376.0000 - val_loss: -22013025538512965861376.0000\n","Epoch 76/300\n","14668/14668 [==============================] - 1s 45us/step - loss: -22527343218454341615616.0000 - val_loss: -23014923344268853510144.0000\n","Epoch 77/300\n","14668/14668 [==============================] - 1s 58us/step - loss: -23546193545282671607808.0000 - val_loss: -24049180681925270962176.0000\n","Epoch 78/300\n","14668/14668 [==============================] - 1s 57us/step - loss: -24597626219818022600704.0000 - val_loss: -25116175562781071769600.0000\n","Epoch 79/300\n","14668/14668 [==============================] - 1s 53us/step - loss: -25682399894725894078464.0000 - val_loss: -26217186601387016847360.0000\n","Epoch 80/300\n","14668/14668 [==============================] - 1s 57us/step - loss: -26801437958377396240384.0000 - val_loss: -27352691049734548226048.0000\n","Epoch 81/300\n","14668/14668 [==============================] - 1s 56us/step - loss: -27955502131338729750528.0000 - val_loss: -28524016535097072156672.0000\n","Epoch 82/300\n","14668/14668 [==============================] - 1s 57us/step - loss: -29145461069797363023872.0000 - val_loss: -29731145880055394074624.0000\n","Epoch 83/300\n","14668/14668 [==============================] - 1s 43us/step - loss: -30372332016182690316288.0000 - val_loss: -30975985405398823731200.0000\n","Epoch 84/300\n","14668/14668 [==============================] - 1s 43us/step - loss: -31636795340110348419072.0000 - val_loss: -32258101526981131632640.0000\n","Epoch 85/300\n","14668/14668 [==============================] - 1s 43us/step - loss: -32939529350372376182784.0000 - val_loss: -33579639468840567439360.0000\n","Epoch 86/300\n","14668/14668 [==============================] - 1s 42us/step - loss: -34282054582929411014656.0000 - val_loss: -34940190731033418661888.0000\n","Epoch 87/300\n","14668/14668 [==============================] - 1s 52us/step - loss: -35664769494587478638592.0000 - val_loss: -36342740019253325332480.0000\n","Epoch 88/300\n","14668/14668 [==============================] - 1s 52us/step - loss: -37088498833586925862912.0000 - val_loss: -37786658730717510369280.0000\n","Epoch 89/300\n","14668/14668 [==============================] - 1s 42us/step - loss: -38554178617905290149888.0000 - val_loss: -39271884711575423025152.0000\n","Epoch 90/300\n","14668/14668 [==============================] - 1s 42us/step - loss: -40062619917956621008896.0000 - val_loss: -40801443482390201630720.0000\n","Epoch 91/300\n","14668/14668 [==============================] - 1s 46us/step - loss: -41615105700215677517824.0000 - val_loss: -42374388099626016178176.0000\n","Epoch 92/300\n","14668/14668 [==============================] - 1s 42us/step - loss: -43212138983723777392640.0000 - val_loss: -43992700266248769896448.0000\n","Epoch 93/300\n","14668/14668 [==============================] - 1s 43us/step - loss: -44855062695957288189952.0000 - val_loss: -45657026716113311891456.0000\n","Epoch 94/300\n","14668/14668 [==============================] - 1s 45us/step - loss: -46544489721927481425920.0000 - val_loss: -47369225575229416275968.0000\n","Epoch 95/300\n","14668/14668 [==============================] - 1s 43us/step - loss: -48281085913988130144256.0000 - val_loss: -49128919633047331012608.0000\n","Epoch 96/300\n","14668/14668 [==============================] - 1s 44us/step - loss: -50066435921452227100672.0000 - val_loss: -50936664349077565079552.0000\n","Epoch 97/300\n","14668/14668 [==============================] - 1s 42us/step - loss: -51901077823153466507264.0000 - val_loss: -52794410789035873140736.0000\n","Epoch 98/300\n","14668/14668 [==============================] - 1s 45us/step - loss: -53786019779405267599360.0000 - val_loss: -54704033678510035828736.0000\n","Epoch 99/300\n","14668/14668 [==============================] - 1s 43us/step - loss: -55722169078240774193152.0000 - val_loss: -56663656830422336143360.0000\n","Epoch 100/300\n","14668/14668 [==============================] - 1s 43us/step - loss: -57710550561836979191808.0000 - val_loss: -58677619429239834017792.0000\n","Epoch 101/300\n","14668/14668 [==============================] - 1s 43us/step - loss: -59752247518458326024192.0000 - val_loss: -60743999381135291318272.0000\n","Epoch 102/300\n","14668/14668 [==============================] - 1s 44us/step - loss: -61848336374735470329856.0000 - val_loss: -62865903337170790252544.0000\n","Epoch 103/300\n","14668/14668 [==============================] - 1s 46us/step - loss: -63999211766108144009216.0000 - val_loss: -65043962030956860145664.0000\n","Epoch 104/300\n","14668/14668 [==============================] - 1s 48us/step - loss: -66206728828058400194560.0000 - val_loss: -67277628631914259677184.0000\n","Epoch 105/300\n","14668/14668 [==============================] - 1s 43us/step - loss: -68471538537674462724096.0000 - val_loss: -69569735810869746466816.0000\n","Epoch 106/300\n","14668/14668 [==============================] - 1s 43us/step - loss: -70794504155298413936640.0000 - val_loss: -71919071202979333799936.0000\n","Epoch 107/300\n","14668/14668 [==============================] - 1s 43us/step - loss: -73176577179647739953152.0000 - val_loss: -74329540665859735814144.0000\n","Epoch 108/300\n","14668/14668 [==============================] - 1s 43us/step - loss: -75619440459876982063104.0000 - val_loss: -76801352095838767153152.0000\n","Epoch 109/300\n","14668/14668 [==============================] - 1s 43us/step - loss: -78122283873698339356672.0000 - val_loss: -79328231723181801472000.0000\n","Epoch 110/300\n","14668/14668 [==============================] - 1s 52us/step - loss: -80558604004580560732160.0000 - val_loss: -81639313940431056666624.0000\n","Epoch 111/300\n","14668/14668 [==============================] - 1s 51us/step - loss: -82863658005737362161664.0000 - val_loss: -83962392872649935028224.0000\n","Epoch 112/300\n","14668/14668 [==============================] - 1s 42us/step - loss: -85208725785857539178496.0000 - val_loss: -86326369760674238693376.0000\n","Epoch 113/300\n","14668/14668 [==============================] - 1s 43us/step - loss: -87596648316784982622208.0000 - val_loss: -88733917686771539247104.0000\n","Epoch 114/300\n","14668/14668 [==============================] - 1s 44us/step - loss: -90028927599963361247232.0000 - val_loss: -91186486257357621821440.0000\n","Epoch 115/300\n","14668/14668 [==============================] - 1s 43us/step - loss: -92506751161048665948160.0000 - val_loss: -93685837884361705259008.0000\n","Epoch 116/300\n","14668/14668 [==============================] - 1s 54us/step - loss: -95031447143134246469632.0000 - val_loss: -96231294809813798617088.0000\n","Epoch 117/300\n","14668/14668 [==============================] - 1s 50us/step - loss: -97603582260431240036352.0000 - val_loss: -98826060265925325619200.0000\n","Epoch 118/300\n","14668/14668 [==============================] - 1s 43us/step - loss: -100224228534222044790784.0000 - val_loss: -101469700224576422674432.0000\n","Epoch 119/300\n","14668/14668 [==============================] - 1s 47us/step - loss: -102894278040763173437440.0000 - val_loss: -104163451518900007600128.0000\n","Epoch 120/300\n","14668/14668 [==============================] - 1s 43us/step - loss: -105614712434590232870912.0000 - val_loss: -106906795189789410721792.0000\n","Epoch 121/300\n","14668/14668 [==============================] - 1s 44us/step - loss: -108386566426007602987008.0000 - val_loss: -109703243305612002459648.0000\n","Epoch 122/300\n","14668/14668 [==============================] - 1s 56us/step - loss: -111210633685102225260544.0000 - val_loss: -112549680854109566009344.0000\n","Epoch 123/300\n","14668/14668 [==============================] - 1s 48us/step - loss: -114088278194630483247104.0000 - val_loss: -115452715567746142699520.0000\n","Epoch 124/300\n","14668/14668 [==============================] - 1s 43us/step - loss: -117019949752065728708608.0000 - val_loss: -118409205412665734725632.0000\n","Epoch 125/300\n","14668/14668 [==============================] - 1s 56us/step - loss: -120006629304533346418688.0000 - val_loss: -121421028899592228306944.0000\n","Epoch 126/300\n","14668/14668 [==============================] - 1s 48us/step - loss: -122938738061153138638848.0000 - val_loss: -124229367378131025920000.0000\n","Epoch 127/300\n","14668/14668 [==============================] - 1s 47us/step - loss: -125728990110607569059840.0000 - val_loss: -127030346812763850932224.0000\n","Epoch 128/300\n","14668/14668 [==============================] - 1s 52us/step - loss: -128552101520902929252352.0000 - val_loss: -129871328216538943586304.0000\n","Epoch 129/300\n","14668/14668 [==============================] - 1s 44us/step - loss: -131414141257909633286144.0000 - val_loss: -132749953113159469367296.0000\n","Epoch 130/300\n","14668/14668 [==============================] - 1s 51us/step - loss: -134316273979264809828352.0000 - val_loss: -135670787261015911301120.0000\n","Epoch 131/300\n","14668/14668 [==============================] - 1s 44us/step - loss: -137203118865084235907072.0000 - val_loss: -138478017473322120380416.0000\n","Epoch 132/300\n","14668/14668 [==============================] - 1s 43us/step - loss: -139946966049956502175744.0000 - val_loss: -141157182154976218054656.0000\n","Epoch 133/300\n","14668/14668 [==============================] - 1s 44us/step - loss: -142600923805707782848512.0000 - val_loss: -143811346002913506885632.0000\n","Epoch 134/300\n","14668/14668 [==============================] - 1s 43us/step - loss: -145271134474058971742208.0000 - val_loss: -146492365293176389369856.0000\n","Epoch 135/300\n","14668/14668 [==============================] - 1s 55us/step - loss: -147969306561710122860544.0000 - val_loss: -149203575256307520765952.0000\n","Epoch 136/300\n","14668/14668 [==============================] - 1s 51us/step - loss: -150696461431509776072704.0000 - val_loss: -151942434331851170512896.0000\n","Epoch 137/300\n","14668/14668 [==============================] - 1s 44us/step - loss: -153453344244360682668032.0000 - val_loss: -154713615863506553274368.0000\n","Epoch 138/300\n","14668/14668 [==============================] - 1s 57us/step - loss: -156241074241179492548608.0000 - val_loss: -157513270989307819065344.0000\n","Epoch 139/300\n","14668/14668 [==============================] - 1s 45us/step - loss: -159060318883187020267520.0000 - val_loss: -160345638803768661245952.0000\n","Epoch 140/300\n","14668/14668 [==============================] - 1s 44us/step - loss: -161911950579161003720704.0000 - val_loss: -163210073082713444712448.0000\n","Epoch 141/300\n","14668/14668 [==============================] - 1s 45us/step - loss: -164795492136674993897472.0000 - val_loss: -166106174365329480744960.0000\n","Epoch 142/300\n","14668/14668 [==============================] - 1s 47us/step - loss: -167550928408554556620800.0000 - val_loss: -168692315977134427340800.0000\n","Epoch 143/300\n","14668/14668 [==============================] - 1s 44us/step - loss: -170128253635194450345984.0000 - val_loss: -171275797967116789874688.0000\n","Epoch 144/300\n","14668/14668 [==============================] - 1s 55us/step - loss: -172723759752293629558784.0000 - val_loss: -173878464579188908097536.0000\n","Epoch 145/300\n","14668/14668 [==============================] - 1s 44us/step - loss: -175339511395616433373184.0000 - val_loss: -176502168781160827584512.0000\n","Epoch 146/300\n","14668/14668 [==============================] - 1s 45us/step - loss: -177976005000130698674176.0000 - val_loss: -179146469237463095181312.0000\n","Epoch 147/300\n","14668/14668 [==============================] - 1s 46us/step - loss: -180633425661693293232128.0000 - val_loss: -181813314868245973434368.0000\n","Epoch 148/300\n","14668/14668 [==============================] - 1s 44us/step - loss: -183313143294990324072448.0000 - val_loss: -184500617668643986079744.0000\n","Epoch 149/300\n","14668/14668 [==============================] - 1s 47us/step - loss: -186015135154817166475264.0000 - val_loss: -187212542958633178103808.0000\n","Epoch 150/300\n","14668/14668 [==============================] - 1s 48us/step - loss: -188740177373381743607808.0000 - val_loss: -189945467294488754913280.0000\n","Epoch 151/300\n","14668/14668 [==============================] - 1s 61us/step - loss: -191488345299700678656000.0000 - val_loss: -192703225517698411659264.0000\n","Epoch 152/300\n","14668/14668 [==============================] - 1s 45us/step - loss: -194260361047349250752512.0000 - val_loss: -195484917281692175040512.0000\n","Epoch 153/300\n","14668/14668 [==============================] - 1s 56us/step - loss: -197047696127483619311616.0000 - val_loss: -198269095219357913448448.0000\n","Epoch 154/300\n","14668/14668 [==============================] - 1s 56us/step - loss: -199783425796935463731200.0000 - val_loss: -200890090344653200031744.0000\n","Epoch 155/300\n","14668/14668 [==============================] - 1s 47us/step - loss: -202237592294286346420224.0000 - val_loss: -203221328861095803224064.0000\n","Epoch 156/300\n","14668/14668 [==============================] - 1s 61us/step - loss: -204561021085086793072640.0000 - val_loss: -205538111621027367747584.0000\n","Epoch 157/300\n","14668/14668 [==============================] - 1s 47us/step - loss: -206881495376979719880704.0000 - val_loss: -207858693753682775769088.0000\n","Epoch 158/300\n","14668/14668 [==============================] - 1s 48us/step - loss: -209209134894651667382272.0000 - val_loss: -210189504444126648598528.0000\n","Epoch 159/300\n","14668/14668 [==============================] - 1s 46us/step - loss: -211548336453170245926912.0000 - val_loss: -212533107651682959884288.0000\n","Epoch 160/300\n","14668/14668 [==============================] - 1s 45us/step - loss: -213900074741045267529728.0000 - val_loss: -214887741585862768459776.0000\n","Epoch 161/300\n","14668/14668 [==============================] - 1s 45us/step - loss: -216264306326234854326272.0000 - val_loss: -217256397334403780444160.0000\n","Epoch 162/300\n","14668/14668 [==============================] - 1s 52us/step - loss: -218641627727519446728704.0000 - val_loss: -219638449202765334839296.0000\n","Epoch 163/300\n","14668/14668 [==============================] - 1s 45us/step - loss: -221032612566185218670592.0000 - val_loss: -222033388641579069079552.0000\n","Epoch 164/300\n","14668/14668 [==============================] - 1s 48us/step - loss: -223437418619280677666816.0000 - val_loss: -224442979548826997620736.0000\n","Epoch 165/300\n","14668/14668 [==============================] - 1s 49us/step - loss: -225856496148517190893568.0000 - val_loss: -226866186266078529716224.0000\n","Epoch 166/300\n","14668/14668 [==============================] - 1s 44us/step - loss: -228289880445806083833856.0000 - val_loss: -229304182347637253472256.0000\n","Epoch 167/300\n","14668/14668 [==============================] - 1s 45us/step - loss: -230737593106810192003072.0000 - val_loss: -231756718003996426502144.0000\n","Epoch 168/300\n","14668/14668 [==============================] - 1s 43us/step - loss: -233200212572048034103296.0000 - val_loss: -234224424215623355072512.0000\n","Epoch 169/300\n","14668/14668 [==============================] - 1s 45us/step - loss: -235678002042345638330368.0000 - val_loss: -236707550040051557597184.0000\n","Epoch 170/300\n","14668/14668 [==============================] - 1s 44us/step - loss: -238170932882325603614720.0000 - val_loss: -239205033256578090795008.0000\n","Epoch 171/300\n","14668/14668 [==============================] - 1s 44us/step - loss: -240679334691125950676992.0000 - val_loss: -241717543728671119900672.0000\n","Epoch 172/300\n","14668/14668 [==============================] - 1s 44us/step - loss: -243203074490357497462784.0000 - val_loss: -244247868284271251685376.0000\n","Epoch 173/300\n","14668/14668 [==============================] - 1s 43us/step - loss: -245742792275055492464640.0000 - val_loss: -246791903157919305170944.0000\n","Epoch 174/300\n","14668/14668 [==============================] - 1s 44us/step - loss: -248298087911385066373120.0000 - val_loss: -249353601711795324583936.0000\n","Epoch 175/300\n","14668/14668 [==============================] - 1s 55us/step - loss: -250869402631751631634432.0000 - val_loss: -251929396024053900247040.0000\n","Epoch 176/300\n","14668/14668 [==============================] - 1s 50us/step - loss: -253456497577119358910464.0000 - val_loss: -254522482817749686943744.0000\n","Epoch 177/300\n","14668/14668 [==============================] - 1s 43us/step - loss: -256059628928250025082880.0000 - val_loss: -257130138366918680117248.0000\n","Epoch 178/300\n","14668/14668 [==============================] - 1s 45us/step - loss: -258679122290361396887552.0000 - val_loss: -259755491517619618447360.0000\n","Epoch 179/300\n","14668/14668 [==============================] - 1s 47us/step - loss: -261315058701227530387456.0000 - val_loss: -262396118721637856051200.0000\n","Epoch 180/300\n","14668/14668 [==============================] - 1s 43us/step - loss: -263967361603339238244352.0000 - val_loss: -265055064633387220205568.0000\n","Epoch 181/300\n","14668/14668 [==============================] - 1s 44us/step - loss: -266636100121485528530944.0000 - val_loss: -267727985827623527776256.0000\n","Epoch 182/300\n","14668/14668 [==============================] - 1s 52us/step - loss: -269321527773814641917952.0000 - val_loss: -270419989148064563593216.0000\n","Epoch 183/300\n","14668/14668 [==============================] - 1s 57us/step - loss: -272014958260046272659456.0000 - val_loss: -273107555488256013369344.0000\n","Epoch 184/300\n","14668/14668 [==============================] - 1s 55us/step - loss: -274650664644679590477824.0000 - val_loss: -275617664440103541407744.0000\n","Epoch 185/300\n","14668/14668 [==============================] - 1s 44us/step - loss: -277060201896825134776320.0000 - val_loss: -277985079887236389928960.0000\n","Epoch 186/300\n","14668/14668 [==============================] - 1s 48us/step - loss: -279425580822838472867840.0000 - val_loss: -280341265447197620568064.0000\n","Epoch 187/300\n","14668/14668 [==============================] - 1s 45us/step - loss: -281785533769772584402944.0000 - val_loss: -282701652321543923957760.0000\n","Epoch 188/300\n","14668/14668 [==============================] - 1s 59us/step - loss: -284153710508235781308416.0000 - val_loss: -285073213290991033778176.0000\n","Epoch 189/300\n","14668/14668 [==============================] - 1s 45us/step - loss: -286532920606460590686208.0000 - val_loss: -287454744279430545276928.0000\n","Epoch 190/300\n","14668/14668 [==============================] - 1s 45us/step - loss: -288922753358758886244352.0000 - val_loss: -289847775931052450643968.0000\n","Epoch 191/300\n","14668/14668 [==============================] - 1s 48us/step - loss: -291324078334442242834432.0000 - val_loss: -292251736628899675635712.0000\n","Epoch 192/300\n","14668/14668 [==============================] - 1s 45us/step - loss: -293736433486541136855040.0000 - val_loss: -294667484623719737851904.0000\n","Epoch 193/300\n","14668/14668 [==============================] - 1s 45us/step - loss: -296160318850938045464576.0000 - val_loss: -297093979398549207515136.0000\n","Epoch 194/300\n","14668/14668 [==============================] - 1s 50us/step - loss: -298595939080435681722368.0000 - val_loss: -299533712973019872231424.0000\n","Epoch 195/300\n","14668/14668 [==============================] - 1s 45us/step - loss: -301043658948181741273088.0000 - val_loss: -301983935176797059022848.0000\n","Epoch 196/300\n","14668/14668 [==============================] - 1s 45us/step - loss: -303502970479578638712832.0000 - val_loss: -304446437678627766140928.0000\n","Epoch 197/300\n","14668/14668 [==============================] - 1s 54us/step - loss: -305974326810191895461888.0000 - val_loss: -306921404360963693477888.0000\n","Epoch 198/300\n","14668/14668 [==============================] - 1s 44us/step - loss: -308457908766853960826880.0000 - val_loss: -309408124861099962007552.0000\n","Epoch 199/300\n","14668/14668 [==============================] - 1s 54us/step - loss: -310953800722974842552320.0000 - val_loss: -311906938785082044841984.0000\n","Epoch 200/300\n","14668/14668 [==============================] - 1s 53us/step - loss: -313461743727102583111680.0000 - val_loss: -314418525394126724136960.0000\n","Epoch 201/300\n","14668/14668 [==============================] - 1s 45us/step - loss: -315982023936508386344960.0000 - val_loss: -316942199581057572929536.0000\n","Epoch 202/300\n","14668/14668 [==============================] - 1s 44us/step - loss: -318514622526219328946176.0000 - val_loss: -319477248060189889789952.0000\n","Epoch 203/300\n","14668/14668 [==============================] - 1s 46us/step - loss: -321059987355699528073216.0000 - val_loss: -322025773893419679088640.0000\n","Epoch 204/300\n","14668/14668 [==============================] - 1s 47us/step - loss: -323607501523496342650880.0000 - val_loss: -324543812054465533444096.0000\n","Epoch 205/300\n","14668/14668 [==============================] - 1s 46us/step - loss: -325963389337431086989312.0000 - val_loss: -326712132899829266251776.0000\n","Epoch 206/300\n","14668/14668 [==============================] - 1s 44us/step - loss: -328084704353555337707520.0000 - val_loss: -328810305264741114707968.0000\n","Epoch 207/300\n","14668/14668 [==============================] - 1s 45us/step - loss: -330037878240268381061120.0000 - val_loss: -330580250503965847846912.0000\n","Epoch 208/300\n","14668/14668 [==============================] - 1s 50us/step - loss: -331760177050972084764672.0000 - val_loss: -332288049801887003705344.0000\n","Epoch 209/300\n","14668/14668 [==============================] - 1s 49us/step - loss: -333463212903725940080640.0000 - val_loss: -333983706953081386172416.0000\n","Epoch 210/300\n","14668/14668 [==============================] - 1s 47us/step - loss: -335153303286463764365312.0000 - val_loss: -335660006815134161829888.0000\n","Epoch 211/300\n","14668/14668 [==============================] - 1s 48us/step - loss: -336827706896041889497088.0000 - val_loss: -337332870549801164341248.0000\n","Epoch 212/300\n","14668/14668 [==============================] - 1s 61us/step - loss: -338502825255250962677760.0000 - val_loss: -339006590614400445448192.0000\n","Epoch 213/300\n","14668/14668 [==============================] - 1s 48us/step - loss: -340176924000486913212416.0000 - val_loss: -340677771872040063598592.0000\n","Epoch 214/300\n","14668/14668 [==============================] - 1s 51us/step - loss: -341850837541789485760512.0000 - val_loss: -342351180627003830173696.0000\n","Epoch 215/300\n","14668/14668 [==============================] - 1s 46us/step - loss: -343526842354817302528000.0000 - val_loss: -344025862150558599610368.0000\n","Epoch 216/300\n","14668/14668 [==============================] - 1s 47us/step - loss: -345204840905382316474368.0000 - val_loss: -345703189309845856583680.0000\n","Epoch 217/300\n","14668/14668 [==============================] - 1s 52us/step - loss: -346885052824716713132032.0000 - val_loss: -347383581805471590252544.0000\n","Epoch 218/300\n","14668/14668 [==============================] - 1s 58us/step - loss: -348567509356773090787328.0000 - val_loss: -349064815166255548858368.0000\n","Epoch 219/300\n","14668/14668 [==============================] - 1s 58us/step - loss: -350158299226552037015552.0000 - val_loss: -350507291181449425715200.0000\n","Epoch 220/300\n","14668/14668 [==============================] - 1s 61us/step - loss: -351544284082524070608896.0000 - val_loss: -351878001193180194668544.0000\n","Epoch 221/300\n","14668/14668 [==============================] - 1s 60us/step - loss: -352905609078975913525248.0000 - val_loss: -353228055316879091171328.0000\n","Epoch 222/300\n","14668/14668 [==============================] - 1s 47us/step - loss: -354241422287639100260352.0000 - val_loss: -354549537582727152271360.0000\n","Epoch 223/300\n","14668/14668 [==============================] - 1s 45us/step - loss: -355561952497192927232000.0000 - val_loss: -355868411125902576975872.0000\n","Epoch 224/300\n","14668/14668 [==============================] - 1s 46us/step - loss: -356880496947225125978112.0000 - val_loss: -357180465165495693213696.0000\n","Epoch 225/300\n","14668/14668 [==============================] - 1s 48us/step - loss: -358187994154569555771392.0000 - val_loss: -358481215270731764465664.0000\n","Epoch 226/300\n","14668/14668 [==============================] - 1s 45us/step - loss: -359487247183214628831232.0000 - val_loss: -359778012269241608175616.0000\n","Epoch 227/300\n","14668/14668 [==============================] - 1s 44us/step - loss: -360785061850319337553920.0000 - val_loss: -361074231991512231575552.0000\n","Epoch 228/300\n","14668/14668 [==============================] - 1s 59us/step - loss: -362083006346855110934528.0000 - val_loss: -362370713092045014040576.0000\n","Epoch 229/300\n","14668/14668 [==============================] - 1s 47us/step - loss: -363381194673948767289344.0000 - val_loss: -363667606042895041167360.0000\n","Epoch 230/300\n","14668/14668 [==============================] - 1s 44us/step - loss: -364679381183391124684800.0000 - val_loss: -364964852178137380814848.0000\n","Epoch 231/300\n","14668/14668 [==============================] - 1s 45us/step - loss: -365977927833426566578176.0000 - val_loss: -366262119250758018793472.0000\n","Epoch 232/300\n","14668/14668 [==============================] - 1s 55us/step - loss: -367276883700641037287424.0000 - val_loss: -367559528807593100181504.0000\n","Epoch 233/300\n","14668/14668 [==============================] - 1s 52us/step - loss: -368576139716129378533376.0000 - val_loss: -368857841972945587535872.0000\n","Epoch 234/300\n","14668/14668 [==============================] - 1s 45us/step - loss: -369875914970740922777600.0000 - val_loss: -370156160610902319562752.0000\n","Epoch 235/300\n","14668/14668 [==============================] - 1s 46us/step - loss: -371176171470650246955008.0000 - val_loss: -371455266851920539549696.0000\n","Epoch 236/300\n","14668/14668 [==============================] - 1s 51us/step - loss: -372477014521732952752128.0000 - val_loss: -372755188363601224138752.0000\n","Epoch 237/300\n","14668/14668 [==============================] - 1s 44us/step - loss: -373778431243227634860032.0000 - val_loss: -374055732425776955392000.0000\n","Epoch 238/300\n","14668/14668 [==============================] - 1s 44us/step - loss: -375080430634964592099328.0000 - val_loss: -375356464177647175335936.0000\n","Epoch 239/300\n","14668/14668 [==============================] - 1s 57us/step - loss: -376383102773848942051328.0000 - val_loss: -376657825210234918928384.0000\n","Epoch 240/300\n","14668/14668 [==============================] - 1s 50us/step - loss: -377686420365635175317504.0000 - val_loss: -377959995598749432807424.0000\n","Epoch 241/300\n","14668/14668 [==============================] - 1s 44us/step - loss: -378990347912083985661952.0000 - val_loss: -379263512071067286896640.0000\n","Epoch 242/300\n","14668/14668 [==============================] - 1s 46us/step - loss: -380295024252282078232576.0000 - val_loss: -380566538789514079371264.0000\n","Epoch 243/300\n","14668/14668 [==============================] - 1s 46us/step - loss: -381600523870633625387008.0000 - val_loss: -381870832430592229900288.0000\n","Epoch 244/300\n","14668/14668 [==============================] - 1s 45us/step - loss: -382906780919034426687488.0000 - val_loss: -383176296157698722889728.0000\n","Epoch 245/300\n","14668/14668 [==============================] - 1s 45us/step - loss: -384213844631273007480832.0000 - val_loss: -384481990775650515943424.0000\n","Epoch 246/300\n","14668/14668 [==============================] - 1s 48us/step - loss: -385521477209428796112896.0000 - val_loss: -385788733117307790819328.0000\n","Epoch 247/300\n","14668/14668 [==============================] - 1s 54us/step - loss: -386830008375454201806848.0000 - val_loss: -387096476277440820281344.0000\n","Epoch 248/300\n","14668/14668 [==============================] - 1s 45us/step - loss: -388139367358848839974912.0000 - val_loss: -388404610792644178608128.0000\n","Epoch 249/300\n","14668/14668 [==============================] - 1s 49us/step - loss: -389449328318890419159040.0000 - val_loss: -389713658603955199934464.0000\n","Epoch 250/300\n","14668/14668 [==============================] - 1s 46us/step - loss: -390760288849614728069120.0000 - val_loss: -391023506594510032338944.0000\n","Epoch 251/300\n","14668/14668 [==============================] - 1s 61us/step - loss: -392072181019987545161728.0000 - val_loss: -392334132569311943852032.0000\n","Epoch 252/300\n","14668/14668 [==============================] - 1s 60us/step - loss: -393384847696507088928768.0000 - val_loss: -393645594752154685407232.0000\n","Epoch 253/300\n","14668/14668 [==============================] - 1s 58us/step - loss: -394698071812303273066496.0000 - val_loss: -394958836995338560077824.0000\n","Epoch 254/300\n","14668/14668 [==============================] - 1s 48us/step - loss: -396012521260903288537088.0000 - val_loss: -396271471406090641473536.0000\n","Epoch 255/300\n","14668/14668 [==============================] - 1s 51us/step - loss: -397327489084014089732096.0000 - val_loss: -397585109966041724747776.0000\n","Epoch 256/300\n","14668/14668 [==============================] - 1s 44us/step - loss: -398643259581954684616704.0000 - val_loss: -398900658563142245154816.0000\n","Epoch 257/300\n","14668/14668 [==============================] - 1s 46us/step - loss: -399959930121885935730688.0000 - val_loss: -400216088128643152216064.0000\n","Epoch 258/300\n","14668/14668 [==============================] - 1s 48us/step - loss: -401277525266663733198848.0000 - val_loss: -401532381569785664634880.0000\n","Epoch 259/300\n","14668/14668 [==============================] - 1s 55us/step - loss: -402596003593488003235840.0000 - val_loss: -402849931872613743722496.0000\n","Epoch 260/300\n","14668/14668 [==============================] - 1s 58us/step - loss: -403915412282692134240256.0000 - val_loss: -404168315426114738585600.0000\n","Epoch 261/300\n","14668/14668 [==============================] - 1s 55us/step - loss: -405235614941650037506048.0000 - val_loss: -405487297635364701732864.0000\n","Epoch 262/300\n","14668/14668 [==============================] - 1s 50us/step - loss: -406556589286938852196352.0000 - val_loss: -406807904097848298307584.0000\n","Epoch 263/300\n","14668/14668 [==============================] - 1s 45us/step - loss: -407878438089547636015104.0000 - val_loss: -408128471200811628625920.0000\n","Epoch 264/300\n","14668/14668 [==============================] - 1s 44us/step - loss: -409201166134320742531072.0000 - val_loss: -409449700655921721507840.0000\n","Epoch 265/300\n","14668/14668 [==============================] - 1s 56us/step - loss: -410524693051593658990592.0000 - val_loss: -410772551406897667768320.0000\n","Epoch 266/300\n","14668/14668 [==============================] - 1s 59us/step - loss: -411849206648962491088896.0000 - val_loss: -412096006286226826985472.0000\n","Epoch 267/300\n","14668/14668 [==============================] - 1s 53us/step - loss: -413174612821213775396864.0000 - val_loss: -413420800077005399785472.0000\n","Epoch 268/300\n","14668/14668 [==============================] - 1s 45us/step - loss: -414500815724083805159424.0000 - val_loss: -414745616947043335405568.0000\n","Epoch 269/300\n","14668/14668 [==============================] - 1s 48us/step - loss: -415827936599829374828544.0000 - val_loss: -416071784489226023731200.0000\n","Epoch 270/300\n","14668/14668 [==============================] - 1s 48us/step - loss: -417155916703924228194304.0000 - val_loss: -417398815464919001989120.0000\n","Epoch 271/300\n","14668/14668 [==============================] - 1s 55us/step - loss: -418484805948091507146752.0000 - val_loss: -418726887945002282909696.0000\n","Epoch 272/300\n","14668/14668 [==============================] - 1s 58us/step - loss: -419814563921520794533888.0000 - val_loss: -420054843535366947864576.0000\n","Epoch 273/300\n","14668/14668 [==============================] - 1s 44us/step - loss: -421145113388767950929920.0000 - val_loss: -421384865785475332308992.0000\n","Epoch 274/300\n","14668/14668 [==============================] - 1s 45us/step - loss: -422476538659379571851264.0000 - val_loss: -422714757312064612466688.0000\n","Epoch 275/300\n","14668/14668 [==============================] - 1s 44us/step - loss: -423808884781633389985792.0000 - val_loss: -424046297802120655536128.0000\n","Epoch 276/300\n","14668/14668 [==============================] - 1s 48us/step - loss: -425142203062422744334336.0000 - val_loss: -425378631367842565455872.0000\n","Epoch 277/300\n","14668/14668 [==============================] - 1s 49us/step - loss: -426476428036824176263168.0000 - val_loss: -426711646149984521289728.0000\n","Epoch 278/300\n","14668/14668 [==============================] - 1s 43us/step - loss: -427811395398981910528000.0000 - val_loss: -428045880438620810117120.0000\n","Epoch 279/300\n","14668/14668 [==============================] - 1s 45us/step - loss: -429147259049925884772352.0000 - val_loss: -429381036011205538349056.0000\n","Epoch 280/300\n","14668/14668 [==============================] - 1s 52us/step - loss: -430483915039650133049344.0000 - val_loss: -430716585758676477804544.0000\n","Epoch 281/300\n","14668/14668 [==============================] - 1s 51us/step - loss: -431821576809547015651328.0000 - val_loss: -432052842759194740260864.0000\n","Epoch 282/300\n","14668/14668 [==============================] - 1s 43us/step - loss: -433159863664825690226688.0000 - val_loss: -433390815308169491775488.0000\n","Epoch 283/300\n","14668/14668 [==============================] - 1s 43us/step - loss: -434499241061780251738112.0000 - val_loss: -434728583002926086094848.0000\n","Epoch 284/300\n","14668/14668 [==============================] - 1s 44us/step - loss: -435839392925580911443968.0000 - val_loss: -436067865164775776321536.0000\n","Epoch 285/300\n","14668/14668 [==============================] - 1s 57us/step - loss: -437180600294599747960832.0000 - val_loss: -437407785784025949405184.0000\n","Epoch 286/300\n","14668/14668 [==============================] - 1s 44us/step - loss: -438522501554472289828864.0000 - val_loss: -438748643594130065195008.0000\n","Epoch 287/300\n","14668/14668 [==============================] - 1s 43us/step - loss: -439865415570368652902400.0000 - val_loss: -440090588556235844354048.0000\n","Epoch 288/300\n","14668/14668 [==============================] - 1s 43us/step - loss: -441209170392472398856192.0000 - val_loss: -441433197570238000922624.0000\n","Epoch 289/300\n","14668/14668 [==============================] - 1s 44us/step - loss: -442553802432761154240512.0000 - val_loss: -442776734087503776055296.0000\n","Epoch 290/300\n","14668/14668 [==============================] - 1s 43us/step - loss: -443899461485355119673344.0000 - val_loss: -444121284510334859608064.0000\n","Epoch 291/300\n","14668/14668 [==============================] - 1s 44us/step - loss: -445245885307379785924608.0000 - val_loss: -445467191824625942134784.0000\n","Epoch 292/300\n","14668/14668 [==============================] - 1s 43us/step - loss: -446593136593068565200896.0000 - val_loss: -446812849079218889293824.0000\n","Epoch 293/300\n","14668/14668 [==============================] - 1s 44us/step - loss: -447941175864999440023552.0000 - val_loss: -448160339214118324011008.0000\n","Epoch 294/300\n","14668/14668 [==============================] - 1s 58us/step - loss: -449290202259157680128000.0000 - val_loss: -449508060171087143501824.0000\n","Epoch 295/300\n","14668/14668 [==============================] - 1s 44us/step - loss: -450640124499970643460096.0000 - val_loss: -450857019940955028979712.0000\n","Epoch 296/300\n","14668/14668 [==============================] - 1s 43us/step - loss: -451990949219409672011776.0000 - val_loss: -452206484929467962621952.0000\n","Epoch 297/300\n","14668/14668 [==============================] - 1s 43us/step - loss: -453342613939394441117696.0000 - val_loss: -453556653771529056681984.0000\n","Epoch 298/300\n","14668/14668 [==============================] - 1s 43us/step - loss: -454695180862901144518656.0000 - val_loss: -454908686560996710416384.0000\n","Epoch 299/300\n","14668/14668 [==============================] - 1s 44us/step - loss: -456048613686028833652736.0000 - val_loss: -456261238334133918236672.0000\n","Epoch 300/300\n","14668/14668 [==============================] - 1s 45us/step - loss: -457402930978296514478080.0000 - val_loss: -457614535462220550111232.0000\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.callbacks.History at 0x7f985c727588>"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"g4LiAkVeU2da"},"source":["## Analizando los resultados\n","\n","¿Qué podemos decir acerca de la cantidad de parámetros del modelo y el número de datos de entrada? ¿Correspondería agregar un término de regularización?\n","\n","Llevemos ahora los audios de entrenamiento y su correspondiente reconstrucción del autoencoder a un archivo midi para poder escucharlos. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"2jrFFjM_U2dd","colab":{}},"source":["reconstruccion = autoencoder.predict(x_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"hdS99sHxU2dn","colab":{}},"source":["# Hacemos una función que reconstruye la nomenclatura de las notas para los archivos midi\n","def get_notas(X):\n","    desnorm = (X*len(le.classes_)).astype(int)\n","    return list(le.classes_[desnorm-1].ravel()) # BORRAR Le agregué el -1 para que no pincharan los índices"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"-VWtWjnAU2dz"},"source":["Grabemos el primero de los audios"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"JYsO2ArRU2d2","colab":{}},"source":["prediction_output = get_notas(reconstruccion[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"roXvVPokU2eG","colab":{}},"source":["offset = 0\n","output_notes = []\n","#  Creamos las notas en base a los patrones originales\n","for pattern in prediction_output:\n","    \n","    # Si el patrón es un acorde\n","    if ('.' in pattern) or pattern.isdigit():\n","        notes_in_chord = pattern.split('.')\n","        notes = []\n","        for current_note in notes_in_chord:\n","            new_note = note.Note(int(current_note))\n","            new_note.storedInstrument = instrument.Piano()\n","            notes.append(new_note)\n","        new_chord = chord.Chord(notes)\n","        new_chord.offset = offset\n","        output_notes.append(new_chord)\n","    \n","    # Si el patrón es una nota\n","    else:\n","        new_note = note.Note(pattern)\n","        new_note.offset = offset\n","        new_note.storedInstrument = instrument.Piano()\n","        output_notes.append(new_note)\n","    \n","    # En cualquier caso, incrementamos el offset para manejar el tiempo de ejecución.\n","    offset += 0.7"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"kCM-0Ug2U2eP","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1593695453067,"user_tz":180,"elapsed":3420,"user":{"displayName":"Julián Ansaldo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhUb7AsWoOmdCsmzYzXTDr9Sws-IR4J0wcrp266tQ=s64","userId":"10643095115217147090"}},"outputId":"778b8e87-ba95-467d-cc96-6011da564387"},"source":["!mkdir output_midi\n","# Grabamos el archivo en una carpeta output_midi\n","midi_stream = stream.Stream(output_notes)\n","midi_stream.write('midi', fp='output_midi/reconstruccion.mid')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["mkdir: cannot create directory ‘output_midi’: File exists\n"],"name":"stdout"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic":{"type":"string"},"text/plain":["'output_midi/reconstruccion.mid'"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"kV-f5YCLU2eY"},"source":["### Autoencoder Sequence to Sequence con LSTM\n","\n","Ahora vamos a probar un autoencoder diseñado para mapear de secuencia a secuencia. \n","Siguiento la arquitectura propuesta para sequence to sequence en el <a href='https://blog.keras.io/building-autoencoders-in-keras.html'>blog de keras </a> vamos a  proponer un encoder de dos layers LSTM y un decoder de una layer con una capa densa que permite recuperar las clases originales.\n","\n","En este apartado, vamos a trabajar con una representación distinta de los datos: podemos afirmar que las diferentes notas son categorías completamente divergente, es decir, no mantienen una relación de ordinalidad entre ellas. Una representación que conserva esta diferencia es agregar al resultado del LabelEncoder una nueva dimensión que codifique con OneHotEncoding las distintas notas posibles. \n","\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"3r7OIVfRU2eb","colab":{}},"source":["def auto_encoder_model(sequence_len, input_dim, latent_dim):\n","    # Encoder\n","    inputs = Input(shape=(sequence_len, input_dim))\n","    encoded = LSTM(input_dim*2, return_sequences=True)(inputs)\n","    encoded = LSTM(latent_dim)(encoded)\n","    \n","    # Decoder\n","    decoded = RepeatVector(sequence_len)(encoded)\n","    decoded = LSTM(input_dim*2, return_sequences=True)(decoded)\n","    decoded = Dense(nclasses, activation='softmax')(decoded)\n","    auto_encoder_model = Model(inputs, decoded)\n","    auto_encoder_model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n","    auto_encoder_model.summary()\n","    return auto_encoder_model\n","    #encoder = Model(inputs, encoded)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ubyN_Y0kU2e2","colab":{}},"source":["input_ids = len(le.classes_)*array_input"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1d3E5nMCywcB","colab_type":"code","colab":{}},"source":["## VERSION ANTERIOR - BORRAR\n","\n","def get_one_hot(input_array, nclasses):\n","    # Mapea los valores de input_array en tantas columnas como indica nclasses. \n","    # Aumenta la dimensión del array de entrada agregando una dimensión para las columnas dummy.\n","    one_hot = tf.one_hot(input_array, nclasses)\n","    with tf.Session() as sess:\n","        return sess.run(one_hot)\n","\n","one_hot_input_sequences = np.squeeze(get_one_hot(input_ids,len(le.classes_)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"dtpmIK1AU2fK","colab":{}},"source":["# OneHotEncoding\n","one_hot_input_sequences = tf.squeeze(tf.one_hot(input_ids, len(le.classes_))).numpy()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ofBkeavRn5yM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593708150745,"user_tz":180,"elapsed":859,"user":{"displayName":"lionel chamorro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GglhTjMhHU8uZtGPAy83V2WmPGyzG8gT4cfIh79aQ=s64","userId":"01475641222516514519"}},"outputId":"f6275b3f-4854-4b75-a8c8-6d9042282725"},"source":["one_hot_input_sequences.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(18335, 10, 256)"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ock4USFBU2fe","colab":{}},"source":["sequence_len = timesteps"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"VcZDMIErU2gH","colab":{}},"source":["latent_dim = 5"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fRT_ksLRaiWa","colab_type":"code","colab":{}},"source":["nclasses = len(le.classes_)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"hHOwdqr4U2gq","colab":{"base_uri":"https://localhost:8080/","height":357},"executionInfo":{"status":"ok","timestamp":1593708413120,"user_tz":180,"elapsed":2440,"user":{"displayName":"lionel chamorro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GglhTjMhHU8uZtGPAy83V2WmPGyzG8gT4cfIh79aQ=s64","userId":"01475641222516514519"}},"outputId":"badbbf6a-ef60-4652-b521-71a536407214"},"source":["model = auto_encoder_model(sequence_len, nclasses, latent_dim)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         (None, 10, 256)           0         \n","_________________________________________________________________\n","lstm_1 (LSTM)                (None, 10, 512)           1574912   \n","_________________________________________________________________\n","lstm_2 (LSTM)                (None, 5)                 10360     \n","_________________________________________________________________\n","repeat_vector_1 (RepeatVecto (None, 10, 5)             0         \n","_________________________________________________________________\n","lstm_3 (LSTM)                (None, 10, 512)           1060864   \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 10, 256)           131328    \n","=================================================================\n","Total params: 2,777,464\n","Trainable params: 2,777,464\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"TXMHqUZFU2g_","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593711352672,"user_tz":180,"elapsed":2932188,"user":{"displayName":"lionel chamorro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GglhTjMhHU8uZtGPAy83V2WmPGyzG8gT4cfIh79aQ=s64","userId":"01475641222516514519"}},"outputId":"1ea8f1c6-da26-4e4e-91ff-ea66035c67f4"},"source":["model.fit(one_hot_input_sequences, one_hot_input_sequences, epochs=150, batch_size=128, shuffle=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 3.8277e-04\n","Epoch 2/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 3.7484e-05\n","Epoch 3/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 1.3184e-06\n","Epoch 4/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 9.5475e-08\n","Epoch 5/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 3.3425e-08\n","Epoch 6/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 1.8752e-08\n","Epoch 7/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 1.2701e-08\n","Epoch 8/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 9.4882e-09\n","Epoch 9/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 7.5579e-09\n","Epoch 10/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 6.2482e-09\n","Epoch 11/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 5.3187e-09\n","Epoch 12/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 4.6236e-09\n","Epoch 13/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 4.0859e-09\n","Epoch 14/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 3.6616e-09\n","Epoch 15/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 3.3098e-09\n","Epoch 16/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 3.0260e-09\n","Epoch 17/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 2.7773e-09\n","Epoch 18/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 2.5702e-09\n","Epoch 19/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 2.3969e-09\n","Epoch 20/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 2.2399e-09\n","Epoch 21/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 2.1008e-09\n","Epoch 22/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 1.9775e-09\n","Epoch 23/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 1.8686e-09\n","Epoch 24/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 1.7727e-09\n","Epoch 25/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 1.6892e-09\n","Epoch 26/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 1.6086e-09\n","Epoch 27/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 1.5351e-09\n","Epoch 28/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 1.4727e-09\n","Epoch 29/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 1.4145e-09\n","Epoch 30/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 1.3582e-09\n","Epoch 31/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 1.3104e-09\n","Epoch 32/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 1.2561e-09\n","Epoch 33/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 1.2123e-09\n","Epoch 34/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 1.1697e-09\n","Epoch 35/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 1.1326e-09\n","Epoch 36/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 1.0962e-09\n","Epoch 37/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 1.0624e-09\n","Epoch 38/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 1.0328e-09\n","Epoch 39/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 1.0010e-09\n","Epoch 40/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 9.7202e-10\n","Epoch 41/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 9.4503e-10\n","Epoch 42/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 9.2163e-10\n","Epoch 43/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 8.9757e-10\n","Epoch 44/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 8.7547e-10\n","Epoch 45/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 8.5563e-10\n","Epoch 46/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 8.3808e-10\n","Epoch 47/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 8.1727e-10\n","Epoch 48/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 7.9972e-10\n","Epoch 49/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 7.8086e-10\n","Epoch 50/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 7.6591e-10\n","Epoch 51/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 7.5161e-10\n","Epoch 52/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 7.3535e-10\n","Epoch 53/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 7.2235e-10\n","Epoch 54/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 7.0999e-10\n","Epoch 55/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 6.9374e-10\n","Epoch 56/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 6.8139e-10\n","Epoch 57/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 6.6968e-10\n","Epoch 58/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 6.5993e-10\n","Epoch 59/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 6.4823e-10\n","Epoch 60/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 6.3717e-10\n","Epoch 61/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 6.2612e-10\n","Epoch 62/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 6.1702e-10\n","Epoch 63/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 6.0857e-10\n","Epoch 64/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 5.9621e-10\n","Epoch 65/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 5.8776e-10\n","Epoch 66/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 5.7801e-10\n","Epoch 67/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 5.7020e-10\n","Epoch 68/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 5.6630e-10\n","Epoch 69/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 5.5525e-10\n","Epoch 70/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 5.4615e-10\n","Epoch 71/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 5.4290e-10\n","Epoch 72/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 5.3575e-10\n","Epoch 73/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 5.2859e-10\n","Epoch 74/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 5.2144e-10\n","Epoch 75/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 5.1364e-10\n","Epoch 76/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 5.0259e-10\n","Epoch 77/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 4.9868e-10\n","Epoch 78/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 4.9478e-10\n","Epoch 79/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 4.8893e-10\n","Epoch 80/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 4.8308e-10\n","Epoch 81/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 4.7593e-10\n","Epoch 82/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 4.6683e-10\n","Epoch 83/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 4.6032e-10\n","Epoch 84/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 4.4862e-10\n","Epoch 85/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 4.4602e-10\n","Epoch 86/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 4.3952e-10\n","Epoch 87/150\n","18335/18335 [==============================] - 21s 1ms/step - loss: 4.3432e-10\n","Epoch 88/150\n","18335/18335 [==============================] - 21s 1ms/step - loss: 4.3172e-10\n","Epoch 89/150\n","18335/18335 [==============================] - 21s 1ms/step - loss: 4.2391e-10\n","Epoch 90/150\n","18335/18335 [==============================] - 21s 1ms/step - loss: 4.2261e-10\n","Epoch 91/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 4.2001e-10\n","Epoch 92/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 4.1091e-10\n","Epoch 93/150\n","18335/18335 [==============================] - 21s 1ms/step - loss: 4.0636e-10\n","Epoch 94/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 3.9953e-10\n","Epoch 95/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 3.9336e-10\n","Epoch 96/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 3.9336e-10\n","Epoch 97/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 3.8880e-10\n","Epoch 98/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 3.8393e-10\n","Epoch 99/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 3.8165e-10\n","Epoch 100/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 3.7775e-10\n","Epoch 101/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 3.7353e-10\n","Epoch 102/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 3.6995e-10\n","Epoch 103/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 3.6865e-10\n","Epoch 104/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 3.6410e-10\n","Epoch 105/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 3.5825e-10\n","Epoch 106/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 3.5239e-10\n","Epoch 107/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 3.4947e-10\n","Epoch 108/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 3.4329e-10\n","Epoch 109/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 3.4069e-10\n","Epoch 110/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 3.4069e-10\n","Epoch 111/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 3.3939e-10\n","Epoch 112/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 3.3484e-10\n","Epoch 113/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 3.3484e-10\n","Epoch 114/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 3.3484e-10\n","Epoch 115/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 3.2964e-10\n","Epoch 116/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 3.2411e-10\n","Epoch 117/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 3.2314e-10\n","Epoch 118/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 3.2314e-10\n","Epoch 119/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 3.2184e-10\n","Epoch 120/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 3.1729e-10\n","Epoch 121/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 3.1729e-10\n","Epoch 122/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 3.1273e-10\n","Epoch 123/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 3.1143e-10\n","Epoch 124/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 3.1013e-10\n","Epoch 125/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 3.0558e-10\n","Epoch 126/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 3.0006e-10\n","Epoch 127/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 2.9908e-10\n","Epoch 128/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 2.9615e-10\n","Epoch 129/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 2.9388e-10\n","Epoch 130/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 2.9388e-10\n","Epoch 131/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 2.9193e-10\n","Epoch 132/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 2.8803e-10\n","Epoch 133/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 2.8803e-10\n","Epoch 134/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 2.8803e-10\n","Epoch 135/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 2.8803e-10\n","Epoch 136/150\n","18335/18335 [==============================] - 19s 1ms/step - loss: 2.8348e-10\n","Epoch 137/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 2.8185e-10\n","Epoch 138/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 2.7632e-10\n","Epoch 139/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 2.7632e-10\n","Epoch 140/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 2.7632e-10\n","Epoch 141/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 2.7600e-10\n","Epoch 142/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 2.7502e-10\n","Epoch 143/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 2.7047e-10\n","Epoch 144/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 2.6982e-10\n","Epoch 145/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 2.7015e-10\n","Epoch 146/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 2.6657e-10\n","Epoch 147/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 2.6462e-10\n","Epoch 148/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 2.6462e-10\n","Epoch 149/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 2.6462e-10\n","Epoch 150/150\n","18335/18335 [==============================] - 20s 1ms/step - loss: 2.5942e-10\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.callbacks.History at 0x7f82d87be1d0>"]},"metadata":{"tags":[]},"execution_count":42}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"qmr47ULwU2hR","colab":{}},"source":["def saveModel(model):\n","    model_json = model.to_json()\n","    with open(\"LSTMAutoencoder.json\", \"w\") as json_file:\n","        json_file.write(model_json)\n","    model.save_weights(\"LSTMAutoencoder.h5\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"gpPLzifqU2hb","colab":{}},"source":["saveModel(model)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"4L8-0EMRU2hk"},"source":["Usamos el modelo para predecir uno de los propios datos de entrada. Observamos que la secuencia se reconstruye casi de forma perfecta. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"jnt1IKQTW6iP","colab":{}},"source":["from keras.models import model_from_json\n","\n","def load_model(fn_json, fn_h5):\n","    with open(fn_json) as f:\n","        model = model_from_json(f.read())\n","    model.load_weights(fn_h5)\n","    return model\n","\n","model = load_model(\"LSTMAutoencoder.json\", \"LSTMAutoencoder.h5\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"a5i9kacHU2hn","colab":{}},"source":["reconstruct =  model.predict(np.expand_dims(one_hot_input_sequences[0], axis=0))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ivapoRtqU2hz","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593708172060,"user_tz":180,"elapsed":811,"user":{"displayName":"lionel chamorro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GglhTjMhHU8uZtGPAy83V2WmPGyzG8gT4cfIh79aQ=s64","userId":"01475641222516514519"}},"outputId":"0b1b1431-16a9-489a-cea2-8670d1c7eceb"},"source":["# La nueva secuencia de notas\n","np.argmax(reconstruct[0],axis=1)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([253, 149, 219,  76, 192, 216, 216, 199, 199, 199])"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"q4qA-RN2U2h-","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593708186481,"user_tz":180,"elapsed":730,"user":{"displayName":"lionel chamorro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GglhTjMhHU8uZtGPAy83V2WmPGyzG8gT4cfIh79aQ=s64","userId":"01475641222516514519"}},"outputId":"1c8e2f89-8423-4dc3-ba20-99fdfebd3af4"},"source":["# La secuencia anterior de notas\n","np.argmax(one_hot_input_sequences[0],axis=1)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"MY07uQ8DU2iH","colab":{}},"source":["def get_midi(note_chord_array, file_name):\n","    offset = 0\n","    output_notes = []\n","    # create note and chord objects based on the values generated by the model\n","    for pattern in note_chord_array:\n","        # pattern is a chord\n","        if ('.' in pattern) or pattern.isdigit():\n","            notes_in_chord = pattern.split('.')\n","            notes = []\n","            for current_note in notes_in_chord:\n","                new_note = note.Note(int(current_note))\n","                new_note.storedInstrument = instrument.Piano()\n","                notes.append(new_note)\n","            new_chord = chord.Chord(notes)\n","            new_chord.offset = offset\n","            output_notes.append(new_chord)\n","        # pattern is a note\n","        else:\n","            new_note = note.Note(pattern)\n","            new_note.offset = offset\n","            new_note.storedInstrument = instrument.Piano()\n","            output_notes.append(new_note)\n","        # increase offset each iteration so that notes do not stack\n","        offset += 0.7\n","    midi_stream = stream.Stream(output_notes)\n","    midi_stream.write('midi', fp='{}.mid'.format(file_name))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"nLs46hp1U2iT","colab":{}},"source":["get_midi(le.classes_[np.argmax(reconstruct[0],axis=1)],'SecuenciaReconstruidaLSTM')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"VLEceuyaU2ij","colab":{}},"source":["get_midi(le.classes_[np.argmax(one_hot_input_sequences[0],axis=1)],'SecuenciaOriginal')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"vFoBmep1U2i8"},"source":["### Usando el modelo para generar datos nuevos\n","\n","El modelo fue entrenado usando secuencias que aparecen en la música de Bach. Lo que hacemos a continuación es partir de una secuencia aleatoria y utilizar la red para generar una secuencia de música nueva. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"l_D-nP1lU2i-","colab":{"base_uri":"https://localhost:8080/","height":187},"executionInfo":{"status":"ok","timestamp":1593708271443,"user_tz":180,"elapsed":760,"user":{"displayName":"lionel chamorro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GglhTjMhHU8uZtGPAy83V2WmPGyzG8gT4cfIh79aQ=s64","userId":"01475641222516514519"}},"outputId":"fdd568a0-ee24-4a1a-d215-05c608a77978"},"source":["#random_seq = get_one_hot(np.random.randint((nclasses - 1), size=10), nclasses)\n","random_seq = (tf.one_hot(np.random.randint((nclasses - 1), size=10), nclasses)).numpy()\n","muestra = le.classes_[np.argmax(random_seq, axis=1)]\n","print(muestra)\n","print('############################')\n","get_midi(muestra, 'Random')\n","long_sequence = [random_seq]\n","range_ = 10\n","for i in range(range_):\n","    new_seq = model.predict(long_sequence[-1].reshape(1, sequence_len, nclasses))[0]\n","    long_sequence.append(new_seq)\n","    \n","long_sequence = np.array(list(reduce(lambda x,y: np.concatenate((x,y)), long_sequence)))\n","output = le.classes_[np.argmax(long_sequence, axis=1)][range_:]\n","print(output)\n","get_midi(output, 'GeneradaLSTM')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['2.6.7' 'B5' '2.8' '5.8' '11.2.5.7' '8.11.2' '1.3.6' 'G3' '1.4' '2.4']\n","############################\n","['6.9' 'F#4' 'B2' 'A4' 'A4' '4.7' '11.3' '9.0.4' '10.2.5' '10.2.5' '6.9'\n"," '9' 'A4' '7.10' '5.11' '5.11' '5.11' 'A4' '1.4' '2.4' 'G4' 'A4' 'G#3'\n"," '7.0' '7.0' 'C5' 'C5' '7.11' 'C5' 'F4' 'G4' '2.5' 'B-4' 'B-4' '5' 'C5'\n"," 'A4' 'D5' '7.10' 'B-4' 'G4' 'A4' 'C5' '0.3' 'C5' 'B-4' 'A4' 'F4' 'B-4'\n"," 'D5' 'C5' 'B-4' 'D5' 'C5' 'B-4' 'A4' 'A4' 'B-4' 'F5' 'D5' 'C5' 'B-4' 'D5'\n"," 'C5' 'D5' 'A4' 'B-4' 'G4' 'G4' 'F4' 'C5' 'B-4' 'C5' 'C5' 'B-4' 'A4' 'A4'\n"," 'G4' 'G4' 'F5' 'C5' 'B-4' 'C5' 'B-4' 'B-4' 'A4' 'B-4' 'B-4' 'A4' 'A4'\n"," 'D5' 'D5' 'B-4' 'B-4' 'B-4' 'A4' 'B-4' 'C5' 'A4' 'A4']\n"],"name":"stdout"}]}]}