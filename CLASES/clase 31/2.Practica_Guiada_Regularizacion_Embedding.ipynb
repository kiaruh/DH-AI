{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2.Practica_Guiada_Regularizacion_Embedding.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"cN6fpDfultZ6","colab_type":"code","colab":{}},"source":["!pip install -U tqdm music21"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QEkBSQ8obDDn","colab_type":"code","colab":{}},"source":["!pip install -U google-api-python-client oauth2client PyDrive"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9MQI74bCsnPx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593693725262,"user_tz":180,"elapsed":3799,"user":{"displayName":"Julián Ansaldo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhUb7AsWoOmdCsmzYzXTDr9Sws-IR4J0wcrp266tQ=s64","userId":"10643095115217147090"}},"outputId":"cb776ec3-edc6-41a5-8787-d3e308ea0ed4"},"source":["import numpy as np\n","from glob import glob\n","from tqdm import tqdm\n","from functools import reduce\n","from music21 import converter, instrument, note, chord, stream\n","from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n","from keras.utils.np_utils import to_categorical\n","from keras.utils import normalize\n","from keras.layers import LSTM, Dense, Dropout, Activation, Embedding, Bidirectional\n","from keras.models import Sequential, model_from_json\n","from sklearn.model_selection import train_test_split\n","from IPython.display import clear_output\n","import matplotlib.pyplot as plt\n","from keras.layers import Conv1D, GlobalAveragePooling1D, MaxPooling1D,RepeatVector\n","import keras\n","import os\n","import tensorflow as tf\n","from keras.layers import Input, Dense, MaxPooling1D, UpSampling1D\n","from keras.models import Model\n","from keras import backend as K\n","from keras.callbacks import TensorBoard\n","from gensim.models import Word2Vec, KeyedVectors"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"dr6gtF6xsnP1","colab_type":"text"},"source":["## Práctica Guiada 2 - Regularización\n","\n","Como hemos visto, uno de los problemas de los autoencoders es el overfitting. Cuando un autoencoder tiene una arquitectura con una gran cantidad de parámetros, corremos el riesgo de que aprenda perfectamente los datos de entrenamiento y pierda la capacidad de generalizar. \n","\n","En esta práctica vamos a regularizar nuestro modelo anterior LSTM.\n","\n","Para observar la calidad de la generalización observamos el entrenamiento sobre conjuntos de train y test.\n","\n","### Preprocesamos los datos\n"]},{"cell_type":"code","metadata":{"id":"ogdW54sKsnP3","colab_type":"code","colab":{}},"source":["def get_notes(audio_file):\n","    midi = converter.parse(audio_file)\n","    instrument_partition = instrument.partitionByInstrument(midi)\n","    audio_features = instrument_partition.parts[0].recurse()\n","    \n","    def get_note_chord(audio_feature):\n","        if isinstance(audio_feature, note.Note):\n","            return str(audio_feature.pitch)\n","        elif isinstance(audio_feature, chord.Chord):\n","            return '.'.join(map(lambda x: str(x), audio_feature.normalOrder))\n","    \n","    return list(filter(lambda x: x!= None, map(get_note_chord, audio_features)))\n","\n","def get_chunks(file_notes):\n","    new_chunks = []\n","    num_chunks = len(file_notes) // 10\n","    for n in range(0,num_chunks):\n","        new_chunks.append(file_notes[n*10:n*10 + 10])\n","    return new_chunks"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"U75qK_j0PuyX","colab":{"base_uri":"https://localhost:8080/","height":104},"executionInfo":{"status":"ok","timestamp":1593693783019,"user_tz":180,"elapsed":52886,"user":{"displayName":"Julián Ansaldo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhUb7AsWoOmdCsmzYzXTDr9Sws-IR4J0wcrp266tQ=s64","userId":"10643095115217147090"}},"outputId":"f333518c-c598-4743-b327-220ced4858c1"},"source":["import os\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","# 1. Authenticate and create the PyDrive client.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","\n","def download_from_drive(local_fn, id):\n","  print('Downloading: %s, id: %s' % (local_fn, id))\n","  downloaded = drive.CreateFile({'id': id})\n","  downloaded.GetContentFile(local_fn)\n","\n","fns = [\n","    ('LSTMSinRegularizanTrTe.h5', '1dglMb7yK-tMocu5ufoyz3ofT5IeLzd5L'), \n","    ('LSTMSinRegularizanTrTe.json', '1cI3-BiytVBsBAVISKwYdgCe_Zd6ArY7D'), \n","    ('LSTMAutoencoder.h5', '1M1YIRGvhtDPWGKzwjldxTD_yrCWsaeWd'), \n","    ('LSTMAutoencoder.json', '1SIZWIIim6wpJ4GW0Kqq2aVFajRVr0zFi'), \n","    ('bach.tar.gz', '179tgDp-U3oPf0DuCIDuA59-L9nfhqBJN'), \n","]\n","\n","for local_fn, id in fns:\n","  download_from_drive(local_fn, id)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading: LSTMSinRegularizanTrTe.h5, id: 1dglMb7yK-tMocu5ufoyz3ofT5IeLzd5L\n","Downloading: LSTMSinRegularizanTrTe.json, id: 1cI3-BiytVBsBAVISKwYdgCe_Zd6ArY7D\n","Downloading: LSTMAutoencoder.h5, id: 1M1YIRGvhtDPWGKzwjldxTD_yrCWsaeWd\n","Downloading: LSTMAutoencoder.json, id: 1SIZWIIim6wpJ4GW0Kqq2aVFajRVr0zFi\n","Downloading: bach.tar.gz, id: 179tgDp-U3oPf0DuCIDuA59-L9nfhqBJN\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GSBJWPmD7Pcx","colab_type":"code","colab":{}},"source":["!tar -xzf bach.tar.gz"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"67n8eB66snP5","colab_type":"code","colab":{}},"source":["nmidis = 400\n","audio_files = sorted(glob(\"./bach/*.mid\"), key=os.path.getsize)[0:nmidis]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MQxOO0cQsnP7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":173},"executionInfo":{"status":"ok","timestamp":1593693960179,"user_tz":180,"elapsed":155760,"user":{"displayName":"Julián Ansaldo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhUb7AsWoOmdCsmzYzXTDr9Sws-IR4J0wcrp266tQ=s64","userId":"10643095115217147090"}},"outputId":"3d475888-1597-4b8d-895a-eef8a909e686"},"source":["midis_notes_chords_by_file = []\n","for file in audio_files:\n","    try:\n","        notes_file = get_notes(file)\n","        midis_notes_chords_by_file.append(notes_file)\n","    except Exception as err:\n","        print(file, err)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["./bach/458b2d957a32475619d157902a430866.mid 'NoneType' object has no attribute 'parts'\n","./bach/b92f0db2ea8e70515dddd1d73fbcfeb1.mid 'NoneType' object has no attribute 'parts'\n","./bach/60fc529f381b1ce1aaccc313215f9fb4.mid 'NoneType' object has no attribute 'parts'\n","./bach/19cf29a73f93f11c14972f647b3bdc4e.mid 'NoneType' object has no attribute 'parts'\n","./bach/24e3ce35ec2f4fcf2cd1adc296799810.mid 'NoneType' object has no attribute 'parts'\n","./bach/bc66a983c37d0dce783d90fa183ee739.mid 'NoneType' object has no attribute 'parts'\n","./bach/0f2a3840813cf4fe6e22dcf73666e12a.mid 'NoneType' object has no attribute 'parts'\n","./bach/327852b1e95de5032bb1db6f7738045f.mid 'NoneType' object has no attribute 'parts'\n","./bach/11c8c6bd558ce7512d454e9a395f1fb7.mid 'NoneType' object has no attribute 'parts'\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ns0_KZKLsnP8","colab_type":"code","colab":{}},"source":["timesteps = 10"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JNrZr8_msnQA","colab_type":"code","colab":{}},"source":["all_chunks = []\n","for file in midis_notes_chords_by_file:\n","    all_chunks = all_chunks + get_chunks(file)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FIgVd86dsnQC","colab_type":"code","colab":{}},"source":["# Pasamos a numpy Array\n","array_input = np.array(all_chunks)\n","# Instanciamos el LabelEncoder\n","le = LabelEncoder()\n","# El LabelEncoder \"aprende\" todas las clases que existen. \n","# El método fit de LE exige un input unidimensional, por eso hacemos reshape.\n","le.fit(array_input.reshape(len(all_chunks)*timesteps))\n","\n","# Usamos el diccionario aprendido por Label Encoder para transformar un array de dos dimensiones\n","notes_ids = le.transform(array_input.reshape(len(all_chunks)*timesteps)).reshape(len(all_chunks),timesteps)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L52Ln9SYsnQE","colab_type":"text"},"source":["Finalmente obtenemos el vector que utilizamos como input para la LSTM:"]},{"cell_type":"code","metadata":{"id":"jQoguJN2snQF","colab_type":"code","colab":{}},"source":["# OneHotEncoding\n","one_hot_input_sequences = tf.squeeze(tf.one_hot(notes_ids, len(le.classes_))).numpy()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O1-EOs22snQG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593693968489,"user_tz":180,"elapsed":156613,"user":{"displayName":"Julián Ansaldo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhUb7AsWoOmdCsmzYzXTDr9Sws-IR4J0wcrp266tQ=s64","userId":"10643095115217147090"}},"outputId":"2236bc3c-1a08-414b-e516-44c7333de43d"},"source":["one_hot_input_sequences.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(18335, 10, 256)"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"y7rPK8bGsnQK","colab_type":"text"},"source":["### Separación train/test"]},{"cell_type":"code","metadata":{"id":"KNVooK-dsnQL","colab_type":"code","colab":{}},"source":["np.random.seed(0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lArNwG0UsnQO","colab_type":"code","colab":{}},"source":["# Seleccionamos el 80% de los indices para train\n","train_index = np.random.randint(0,one_hot_input_sequences.shape[0],int(0.8 * one_hot_input_sequences.shape[0]))\n","X_train = one_hot_input_sequences[train_index,:,:]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uQT251OwsnQR","colab_type":"code","colab":{}},"source":["# Fancy indexing con la lista de test\n","test_index =  [x for x in range(one_hot_input_sequences.shape[0]) if x not in train_index]\n","X_test = one_hot_input_sequences[test_index,:,:]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IbEHxT9IsnQW","colab_type":"text"},"source":["## Implementación del modelo"]},{"cell_type":"code","metadata":{"id":"7zmoS0BvsnQY","colab_type":"code","colab":{}},"source":["def auto_encoder_model(sequence_len, input_dim, latent_dim):\n","    # Encoder\n","    inputs = Input(shape=(sequence_len, input_dim))\n","    encoded = LSTM(input_dim*2, return_sequences=True)(inputs)\n","    encoded = LSTM(latent_dim)(encoded)\n","    # Decoder\n","    decoded = RepeatVector(sequence_len)(encoded)\n","    decoded = LSTM(input_dim*2, return_sequences=True)(decoded)\n","    decoded = Dense(input_dim, activation='softmax')(decoded)\n","    auto_encoder_model = Model(inputs, decoded)\n","    auto_encoder_model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n","    auto_encoder_model.summary()\n","    return auto_encoder_model\n","    #encoder = Model(inputs, encoded)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4nwYaCBYsnQc","colab_type":"code","colab":{}},"source":["def save_model(model,name):\n","    model_json = model.to_json()\n","    with open(\"{}.json\".format(name), \"w\") as json_file:\n","        json_file.write(model_json)\n","    model.save_weights(\"{}.h5\".format(name))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jXWkwb6OsnQg","colab_type":"code","colab":{}},"source":["# Seteamos la reducción de dimensiones deseada\n","latent_dim = 5"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nApEbCQAsnQi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":364},"executionInfo":{"status":"ok","timestamp":1593693970027,"user_tz":180,"elapsed":153683,"user":{"displayName":"Julián Ansaldo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhUb7AsWoOmdCsmzYzXTDr9Sws-IR4J0wcrp266tQ=s64","userId":"10643095115217147090"}},"outputId":"a8dde3cf-502e-4832-a4d2-42cd1768e8b2"},"source":["model = auto_encoder_model(timesteps, len(le.classes_), latent_dim)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         (None, 10, 256)           0         \n","_________________________________________________________________\n","lstm_1 (LSTM)                (None, 10, 512)           1574912   \n","_________________________________________________________________\n","lstm_2 (LSTM)                (None, 5)                 10360     \n","_________________________________________________________________\n","repeat_vector_1 (RepeatVecto (None, 10, 5)             0         \n","_________________________________________________________________\n","lstm_3 (LSTM)                (None, 10, 512)           1060864   \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 10, 256)           131328    \n","=================================================================\n","Total params: 2,777,464\n","Trainable params: 2,777,464\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XqXopn7MsnQk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593695341268,"user_tz":180,"elapsed":1524455,"user":{"displayName":"Julián Ansaldo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhUb7AsWoOmdCsmzYzXTDr9Sws-IR4J0wcrp266tQ=s64","userId":"10643095115217147090"}},"outputId":"b41e0f1e-c1e1-4ddf-a581-90bdeb134bf8"},"source":["model.fit(X_train, X_train, \n","          epochs=150, batch_size=128, shuffle=True,\n","          callbacks=[TensorBoard(log_dir='/tmp/autoencoder')],\n","          validation_data = (X_test, X_test))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train on 14668 samples, validate on 8205 samples\n","Epoch 1/150\n","14668/14668 [==============================] - 12s 828us/step - loss: 4.0725 - val_loss: 3.8503\n","Epoch 2/150\n","14668/14668 [==============================] - 9s 603us/step - loss: 3.7744 - val_loss: 3.6924\n","Epoch 3/150\n","14668/14668 [==============================] - 9s 623us/step - loss: 3.6038 - val_loss: 3.5899\n","Epoch 4/150\n","14668/14668 [==============================] - 9s 620us/step - loss: 3.4861 - val_loss: 3.4957\n","Epoch 5/150\n","14668/14668 [==============================] - 9s 637us/step - loss: 3.4032 - val_loss: 3.4017\n","Epoch 6/150\n","14668/14668 [==============================] - 9s 620us/step - loss: 3.2653 - val_loss: 3.2166\n","Epoch 7/150\n","14668/14668 [==============================] - 9s 608us/step - loss: 3.1480 - val_loss: 3.1592\n","Epoch 8/150\n","14668/14668 [==============================] - 9s 614us/step - loss: 3.0724 - val_loss: 3.0711\n","Epoch 9/150\n","14668/14668 [==============================] - 9s 611us/step - loss: 2.9973 - val_loss: 3.0085\n","Epoch 10/150\n","14668/14668 [==============================] - 9s 639us/step - loss: 2.9391 - val_loss: 2.9866\n","Epoch 11/150\n","14668/14668 [==============================] - 9s 608us/step - loss: 2.8973 - val_loss: 2.9750\n","Epoch 12/150\n","14668/14668 [==============================] - 9s 612us/step - loss: 2.8618 - val_loss: 2.9595\n","Epoch 13/150\n","14668/14668 [==============================] - 9s 625us/step - loss: 2.8284 - val_loss: 2.9366\n","Epoch 14/150\n","14668/14668 [==============================] - 9s 621us/step - loss: 2.7994 - val_loss: 2.9279\n","Epoch 15/150\n","14668/14668 [==============================] - 9s 614us/step - loss: 2.7719 - val_loss: 2.9392\n","Epoch 16/150\n","14668/14668 [==============================] - 9s 592us/step - loss: 2.7461 - val_loss: 2.9196\n","Epoch 17/150\n","14668/14668 [==============================] - 9s 598us/step - loss: 2.7181 - val_loss: 2.9160\n","Epoch 18/150\n","14668/14668 [==============================] - 9s 602us/step - loss: 2.6919 - val_loss: 2.9248\n","Epoch 19/150\n","14668/14668 [==============================] - 9s 592us/step - loss: 2.6650 - val_loss: 2.9207\n","Epoch 20/150\n","14668/14668 [==============================] - 9s 610us/step - loss: 2.6401 - val_loss: 2.9110\n","Epoch 21/150\n","14668/14668 [==============================] - 9s 640us/step - loss: 2.6141 - val_loss: 2.9249\n","Epoch 22/150\n","14668/14668 [==============================] - 9s 623us/step - loss: 2.5905 - val_loss: 2.9354\n","Epoch 23/150\n","14668/14668 [==============================] - 9s 620us/step - loss: 2.5641 - val_loss: 2.9439\n","Epoch 24/150\n","14668/14668 [==============================] - 9s 599us/step - loss: 2.5386 - val_loss: 2.9450\n","Epoch 25/150\n","14668/14668 [==============================] - 9s 638us/step - loss: 2.5135 - val_loss: 2.9450\n","Epoch 26/150\n","14668/14668 [==============================] - 9s 600us/step - loss: 2.4866 - val_loss: 2.9469\n","Epoch 27/150\n","14668/14668 [==============================] - 9s 622us/step - loss: 2.4607 - val_loss: 2.9553\n","Epoch 28/150\n","14668/14668 [==============================] - 9s 605us/step - loss: 2.4363 - val_loss: 2.9578\n","Epoch 29/150\n","14668/14668 [==============================] - 9s 630us/step - loss: 2.4115 - val_loss: 2.9578\n","Epoch 30/150\n","14668/14668 [==============================] - 9s 618us/step - loss: 2.3857 - val_loss: 2.9781\n","Epoch 31/150\n","14668/14668 [==============================] - 9s 612us/step - loss: 2.3596 - val_loss: 2.9808\n","Epoch 32/150\n","14668/14668 [==============================] - 9s 612us/step - loss: 2.3333 - val_loss: 3.0032\n","Epoch 33/150\n","14668/14668 [==============================] - 9s 598us/step - loss: 2.3104 - val_loss: 2.9981\n","Epoch 34/150\n","14668/14668 [==============================] - 9s 594us/step - loss: 2.2832 - val_loss: 3.0130\n","Epoch 35/150\n","14668/14668 [==============================] - 9s 606us/step - loss: 2.2592 - val_loss: 3.0093\n","Epoch 36/150\n","14668/14668 [==============================] - 9s 611us/step - loss: 2.2324 - val_loss: 3.0353\n","Epoch 37/150\n","14668/14668 [==============================] - 9s 627us/step - loss: 2.2082 - val_loss: 3.0465\n","Epoch 38/150\n","14668/14668 [==============================] - 10s 659us/step - loss: 2.1846 - val_loss: 3.0535\n","Epoch 39/150\n","14668/14668 [==============================] - 9s 622us/step - loss: 2.1598 - val_loss: 3.0692\n","Epoch 40/150\n","14668/14668 [==============================] - 10s 660us/step - loss: 2.1337 - val_loss: 3.0692\n","Epoch 41/150\n","14668/14668 [==============================] - 9s 628us/step - loss: 2.1088 - val_loss: 3.1024\n","Epoch 42/150\n","14668/14668 [==============================] - 9s 624us/step - loss: 2.0855 - val_loss: 3.1135\n","Epoch 43/150\n","14668/14668 [==============================] - 10s 648us/step - loss: 2.0614 - val_loss: 3.1076\n","Epoch 44/150\n","14668/14668 [==============================] - 9s 629us/step - loss: 2.0372 - val_loss: 3.1265\n","Epoch 45/150\n","14668/14668 [==============================] - 9s 632us/step - loss: 2.0129 - val_loss: 3.1381\n","Epoch 46/150\n","14668/14668 [==============================] - 9s 627us/step - loss: 1.9876 - val_loss: 3.1652\n","Epoch 47/150\n","14668/14668 [==============================] - 9s 628us/step - loss: 1.9653 - val_loss: 3.1673\n","Epoch 48/150\n","14668/14668 [==============================] - 10s 659us/step - loss: 1.9391 - val_loss: 3.1903\n","Epoch 49/150\n","14668/14668 [==============================] - 9s 607us/step - loss: 1.9177 - val_loss: 3.2190\n","Epoch 50/150\n","14668/14668 [==============================] - 9s 597us/step - loss: 1.8953 - val_loss: 3.2119\n","Epoch 51/150\n","14668/14668 [==============================] - 9s 607us/step - loss: 1.8712 - val_loss: 3.2356\n","Epoch 52/150\n","14668/14668 [==============================] - 9s 585us/step - loss: 1.8460 - val_loss: 3.2528\n","Epoch 53/150\n","14668/14668 [==============================] - 9s 594us/step - loss: 1.8261 - val_loss: 3.2694\n","Epoch 54/150\n","14668/14668 [==============================] - 9s 609us/step - loss: 1.8039 - val_loss: 3.2782\n","Epoch 55/150\n","14668/14668 [==============================] - 9s 629us/step - loss: 1.7775 - val_loss: 3.2990\n","Epoch 56/150\n","14668/14668 [==============================] - 9s 641us/step - loss: 1.7578 - val_loss: 3.3135\n","Epoch 57/150\n","14668/14668 [==============================] - 9s 601us/step - loss: 1.7367 - val_loss: 3.3211\n","Epoch 58/150\n","14668/14668 [==============================] - 9s 603us/step - loss: 1.7151 - val_loss: 3.3304\n","Epoch 59/150\n","14668/14668 [==============================] - 9s 591us/step - loss: 1.6906 - val_loss: 3.3632\n","Epoch 60/150\n","14668/14668 [==============================] - 9s 603us/step - loss: 1.6701 - val_loss: 3.3857\n","Epoch 61/150\n","14668/14668 [==============================] - 9s 581us/step - loss: 1.6472 - val_loss: 3.4070\n","Epoch 62/150\n","14668/14668 [==============================] - 9s 600us/step - loss: 1.6285 - val_loss: 3.4368\n","Epoch 63/150\n","14668/14668 [==============================] - 9s 606us/step - loss: 1.6083 - val_loss: 3.4350\n","Epoch 64/150\n","14668/14668 [==============================] - 9s 633us/step - loss: 1.5875 - val_loss: 3.4552\n","Epoch 65/150\n","14668/14668 [==============================] - 9s 628us/step - loss: 1.5660 - val_loss: 3.4664\n","Epoch 66/150\n","14668/14668 [==============================] - 9s 642us/step - loss: 1.5479 - val_loss: 3.4956\n","Epoch 67/150\n","14668/14668 [==============================] - 10s 652us/step - loss: 1.5284 - val_loss: 3.5109\n","Epoch 68/150\n","14668/14668 [==============================] - 9s 640us/step - loss: 1.5075 - val_loss: 3.5428\n","Epoch 69/150\n","14668/14668 [==============================] - 9s 637us/step - loss: 1.4865 - val_loss: 3.5440\n","Epoch 70/150\n","14668/14668 [==============================] - 9s 643us/step - loss: 1.4705 - val_loss: 3.5776\n","Epoch 71/150\n","14668/14668 [==============================] - 9s 621us/step - loss: 1.4514 - val_loss: 3.5691\n","Epoch 72/150\n","14668/14668 [==============================] - 9s 611us/step - loss: 1.4298 - val_loss: 3.6160\n","Epoch 73/150\n","14668/14668 [==============================] - 9s 633us/step - loss: 1.4158 - val_loss: 3.6354\n","Epoch 74/150\n","14668/14668 [==============================] - 9s 632us/step - loss: 1.3953 - val_loss: 3.6419\n","Epoch 75/150\n","14668/14668 [==============================] - 9s 632us/step - loss: 1.3780 - val_loss: 3.6655\n","Epoch 76/150\n","14668/14668 [==============================] - 9s 630us/step - loss: 1.3605 - val_loss: 3.6885\n","Epoch 77/150\n","14668/14668 [==============================] - 9s 631us/step - loss: 1.3451 - val_loss: 3.7113\n","Epoch 78/150\n","14668/14668 [==============================] - 9s 647us/step - loss: 1.3227 - val_loss: 3.7357\n","Epoch 79/150\n","14668/14668 [==============================] - 9s 647us/step - loss: 1.3135 - val_loss: 3.7505\n","Epoch 80/150\n","14668/14668 [==============================] - 10s 649us/step - loss: 1.2932 - val_loss: 3.7669\n","Epoch 81/150\n","14668/14668 [==============================] - 9s 626us/step - loss: 1.2791 - val_loss: 3.7911\n","Epoch 82/150\n","14668/14668 [==============================] - 9s 622us/step - loss: 1.2609 - val_loss: 3.8314\n","Epoch 83/150\n","14668/14668 [==============================] - 9s 613us/step - loss: 1.2480 - val_loss: 3.8342\n","Epoch 84/150\n","14668/14668 [==============================] - 9s 644us/step - loss: 1.2320 - val_loss: 3.8503\n","Epoch 85/150\n","14668/14668 [==============================] - 9s 629us/step - loss: 1.2184 - val_loss: 3.8625\n","Epoch 86/150\n","14668/14668 [==============================] - 9s 635us/step - loss: 1.2017 - val_loss: 3.8807\n","Epoch 87/150\n","14668/14668 [==============================] - 10s 648us/step - loss: 1.1877 - val_loss: 3.9013\n","Epoch 88/150\n","14668/14668 [==============================] - 9s 632us/step - loss: 1.1724 - val_loss: 3.9385\n","Epoch 89/150\n","14668/14668 [==============================] - 9s 628us/step - loss: 1.1616 - val_loss: 3.9373\n","Epoch 90/150\n","14668/14668 [==============================] - 10s 656us/step - loss: 1.1468 - val_loss: 3.9575\n","Epoch 91/150\n","14668/14668 [==============================] - 9s 634us/step - loss: 1.1330 - val_loss: 3.9907\n","Epoch 92/150\n","14668/14668 [==============================] - 9s 633us/step - loss: 1.1201 - val_loss: 4.0058\n","Epoch 93/150\n","14668/14668 [==============================] - 9s 629us/step - loss: 1.1047 - val_loss: 4.0261\n","Epoch 94/150\n","14668/14668 [==============================] - 9s 617us/step - loss: 1.0957 - val_loss: 4.0457\n","Epoch 95/150\n","14668/14668 [==============================] - 9s 612us/step - loss: 1.0783 - val_loss: 4.0893\n","Epoch 96/150\n","14668/14668 [==============================] - 9s 617us/step - loss: 1.0682 - val_loss: 4.1060\n","Epoch 97/150\n","14668/14668 [==============================] - 9s 621us/step - loss: 1.0602 - val_loss: 4.1323\n","Epoch 98/150\n","14668/14668 [==============================] - 9s 626us/step - loss: 1.0452 - val_loss: 4.1128\n","Epoch 99/150\n","14668/14668 [==============================] - 9s 634us/step - loss: 1.0341 - val_loss: 4.1379\n","Epoch 100/150\n","14668/14668 [==============================] - 9s 630us/step - loss: 1.0208 - val_loss: 4.1634\n","Epoch 101/150\n","14668/14668 [==============================] - 9s 634us/step - loss: 1.0124 - val_loss: 4.1861\n","Epoch 102/150\n","14668/14668 [==============================] - 9s 634us/step - loss: 1.0025 - val_loss: 4.2079\n","Epoch 103/150\n","14668/14668 [==============================] - 9s 638us/step - loss: 0.9909 - val_loss: 4.2484\n","Epoch 104/150\n","14668/14668 [==============================] - 9s 639us/step - loss: 0.9813 - val_loss: 4.2595\n","Epoch 105/150\n","14668/14668 [==============================] - 9s 637us/step - loss: 0.9707 - val_loss: 4.2658\n","Epoch 106/150\n","14668/14668 [==============================] - 9s 625us/step - loss: 0.9620 - val_loss: 4.3008\n","Epoch 107/150\n","14668/14668 [==============================] - 10s 648us/step - loss: 0.9517 - val_loss: 4.3036\n","Epoch 108/150\n","14668/14668 [==============================] - 9s 645us/step - loss: 0.9390 - val_loss: 4.3276\n","Epoch 109/150\n","14668/14668 [==============================] - 9s 618us/step - loss: 0.9330 - val_loss: 4.3498\n","Epoch 110/150\n","14668/14668 [==============================] - 9s 639us/step - loss: 0.9211 - val_loss: 4.3691\n","Epoch 111/150\n","14668/14668 [==============================] - 9s 632us/step - loss: 0.9144 - val_loss: 4.3773\n","Epoch 112/150\n","14668/14668 [==============================] - 10s 668us/step - loss: 0.9029 - val_loss: 4.3892\n","Epoch 113/150\n","14668/14668 [==============================] - 9s 615us/step - loss: 0.8977 - val_loss: 4.4268\n","Epoch 114/150\n","14668/14668 [==============================] - 9s 637us/step - loss: 0.8876 - val_loss: 4.4402\n","Epoch 115/150\n","14668/14668 [==============================] - 9s 625us/step - loss: 0.8799 - val_loss: 4.4431\n","Epoch 116/150\n","14668/14668 [==============================] - 9s 611us/step - loss: 0.8692 - val_loss: 4.4513\n","Epoch 117/150\n","14668/14668 [==============================] - 9s 604us/step - loss: 0.8624 - val_loss: 4.5025\n","Epoch 118/150\n","14668/14668 [==============================] - 9s 610us/step - loss: 0.8546 - val_loss: 4.5053\n","Epoch 119/150\n","14668/14668 [==============================] - 9s 595us/step - loss: 0.8481 - val_loss: 4.5332\n","Epoch 120/150\n","14668/14668 [==============================] - 9s 612us/step - loss: 0.8383 - val_loss: 4.5458\n","Epoch 121/150\n","14668/14668 [==============================] - 9s 587us/step - loss: 0.8311 - val_loss: 4.5563\n","Epoch 122/150\n","14668/14668 [==============================] - 9s 623us/step - loss: 0.8244 - val_loss: 4.6011\n","Epoch 123/150\n","14668/14668 [==============================] - 9s 595us/step - loss: 0.8213 - val_loss: 4.5954\n","Epoch 124/150\n","14668/14668 [==============================] - 9s 601us/step - loss: 0.8121 - val_loss: 4.6210\n","Epoch 125/150\n","14668/14668 [==============================] - 9s 604us/step - loss: 0.8036 - val_loss: 4.6304\n","Epoch 126/150\n","14668/14668 [==============================] - 9s 621us/step - loss: 0.8015 - val_loss: 4.6490\n","Epoch 127/150\n","14668/14668 [==============================] - 9s 609us/step - loss: 0.7918 - val_loss: 4.6787\n","Epoch 128/150\n","14668/14668 [==============================] - 9s 619us/step - loss: 0.7844 - val_loss: 4.6667\n","Epoch 129/150\n","14668/14668 [==============================] - 9s 615us/step - loss: 0.7797 - val_loss: 4.6930\n","Epoch 130/150\n","14668/14668 [==============================] - 9s 598us/step - loss: 0.7735 - val_loss: 4.7342\n","Epoch 131/150\n","14668/14668 [==============================] - 9s 616us/step - loss: 0.7658 - val_loss: 4.7384\n","Epoch 132/150\n","14668/14668 [==============================] - 9s 617us/step - loss: 0.7606 - val_loss: 4.7606\n","Epoch 133/150\n","14668/14668 [==============================] - 9s 618us/step - loss: 0.7580 - val_loss: 4.7867\n","Epoch 134/150\n","14668/14668 [==============================] - 9s 614us/step - loss: 0.7503 - val_loss: 4.7844\n","Epoch 135/150\n","14668/14668 [==============================] - 9s 617us/step - loss: 0.7458 - val_loss: 4.7886\n","Epoch 136/150\n","14668/14668 [==============================] - 9s 611us/step - loss: 0.7379 - val_loss: 4.8530\n","Epoch 137/150\n","14668/14668 [==============================] - 9s 619us/step - loss: 0.7399 - val_loss: 4.8400\n","Epoch 138/150\n","14668/14668 [==============================] - 9s 624us/step - loss: 0.7295 - val_loss: 4.8384\n","Epoch 139/150\n","14668/14668 [==============================] - 9s 602us/step - loss: 0.7231 - val_loss: 4.8480\n","Epoch 140/150\n","14668/14668 [==============================] - 9s 612us/step - loss: 0.7188 - val_loss: 4.8781\n","Epoch 141/150\n","14668/14668 [==============================] - 9s 643us/step - loss: 0.7140 - val_loss: 4.8973\n","Epoch 142/150\n","14668/14668 [==============================] - 9s 615us/step - loss: 0.7116 - val_loss: 4.9130\n","Epoch 143/150\n","14668/14668 [==============================] - 9s 610us/step - loss: 0.7030 - val_loss: 4.9189\n","Epoch 144/150\n","14668/14668 [==============================] - 9s 613us/step - loss: 0.7011 - val_loss: 4.9492\n","Epoch 145/150\n","14668/14668 [==============================] - 9s 611us/step - loss: 0.7012 - val_loss: 4.9630\n","Epoch 146/150\n","14668/14668 [==============================] - 9s 612us/step - loss: 0.6880 - val_loss: 4.9833\n","Epoch 147/150\n","14668/14668 [==============================] - 9s 595us/step - loss: 0.6874 - val_loss: 4.9989\n","Epoch 148/150\n","14668/14668 [==============================] - 9s 598us/step - loss: 0.6822 - val_loss: 5.0051\n","Epoch 149/150\n","14668/14668 [==============================] - 9s 624us/step - loss: 0.6771 - val_loss: 5.0095\n","Epoch 150/150\n","14668/14668 [==============================] - 9s 614us/step - loss: 0.6717 - val_loss: 5.0529\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.callbacks.History at 0x7f3c55c6b630>"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"XlhoSnZPsnQm","colab_type":"code","colab":{}},"source":["save_model(model,'LSTMSinRegularizanTrTe')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KptRvqnfcDSX","colab_type":"code","colab":{}},"source":["from keras.models import model_from_json\n","\n","def load_model(fn_json, fn_h5):\n","    with open(fn_json) as f:\n","        model = model_from_json(f.read())\n","    model.load_weights(fn_h5)\n","    return model\n","\n","model = load_model(\"LSTMSinRegularizanTrTe.json\", \"LSTMSinRegularizanTrTe.h5\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4wyEMgBMsnQq","colab_type":"text"},"source":["### Regularización L1 y L2\n","\n","Ahora vamos a agregar un término de regularización L1 sobre la capa densa del modelo para intentar evitar que las curvas de loss de train y validation se separen tan abruptamente en unas pocas epochs. \n","\n","La fuerte separación entre ambas curvas demuestra que los parámetros del modelo están \"aprendiendo\" los datos de entrenamiento. \n","\n","Los términos de regularización permiten aplicar penalidades sobre los parámetros de las capas. Estas penalidades se incorporan a la función de loss que la red optimiza y sirven para restarle complejidad al modelo ajustado y así evitar un rápido overfitting. El término de penalización se calcula a partir de alguna función sobre los parámetros. La elección es agregar un término de penalización que sea una fracción (10e-5) de la norma l1 (la suma de los valores absolutos) y la norma l2 (la raíz cuadrada de la suma de los cuadrados) de los pesos de la red. \n"]},{"cell_type":"code","metadata":{"id":"atALXmoMsnQq","colab_type":"code","colab":{}},"source":["from keras import regularizers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5XYzaFIOsnQs","colab_type":"code","colab":{}},"source":["def auto_encoder_model_regularized(sequence_len, input_dim, latent_dim):\n","    # Encoder\n","    inputs = Input(shape=(sequence_len, input_dim))\n","    encoded = LSTM(input_dim*2, return_sequences=True)(inputs)\n","    encoded = LSTM(latent_dim)(encoded)\n","    # Decoder\n","    decoded = RepeatVector(sequence_len)(encoded)\n","    decoded = LSTM(input_dim*2, return_sequences=True)(decoded)\n","    decoded = Dense(len(le.classes_), activation='softmax',\n","                    activity_regularizer=regularizers.l2(10e-3))(decoded)\n","    auto_encoder_model = Model(inputs, decoded)\n","    auto_encoder_model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n","    auto_encoder_model.summary()\n","    return auto_encoder_model\n","    #encoder = Model(inputs, encoded)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZATvTz-DsnQu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":364},"executionInfo":{"status":"ok","timestamp":1593695543273,"user_tz":180,"elapsed":2274,"user":{"displayName":"Julián Ansaldo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhUb7AsWoOmdCsmzYzXTDr9Sws-IR4J0wcrp266tQ=s64","userId":"10643095115217147090"}},"outputId":"9776c80e-9103-44d9-aecc-f3878c16539b"},"source":["model = auto_encoder_model_regularized(timesteps, len(le.classes_), latent_dim)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_2 (InputLayer)         (None, 10, 256)           0         \n","_________________________________________________________________\n","lstm_4 (LSTM)                (None, 10, 512)           1574912   \n","_________________________________________________________________\n","lstm_5 (LSTM)                (None, 5)                 10360     \n","_________________________________________________________________\n","repeat_vector_2 (RepeatVecto (None, 10, 5)             0         \n","_________________________________________________________________\n","lstm_6 (LSTM)                (None, 10, 512)           1060864   \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 10, 256)           131328    \n","=================================================================\n","Total params: 2,777,464\n","Trainable params: 2,777,464\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sjNO_vIRsnQx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593695907055,"user_tz":180,"elapsed":365431,"user":{"displayName":"Julián Ansaldo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhUb7AsWoOmdCsmzYzXTDr9Sws-IR4J0wcrp266tQ=s64","userId":"10643095115217147090"}},"outputId":"2648f577-5cf8-4b76-fdd3-2c4cc0be4d92"},"source":["model.fit(X_train, X_train, \n","          epochs=40, batch_size=128, shuffle=True,\n","          callbacks=[TensorBoard(log_dir='/tmp/autoencoder')],\n","            validation_data = (X_test, X_test))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train on 14668 samples, validate on 8205 samples\n","Epoch 1/40\n","  512/14668 [>.............................] - ETA: 48s - loss: 5.4676 "],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.222599). Check your callbacks.\n","  % (hook_name, delta_t_median), RuntimeWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["14668/14668 [==============================] - 11s 724us/step - loss: 4.3569 - val_loss: 4.1757\n","Epoch 2/40\n","14668/14668 [==============================] - 9s 591us/step - loss: 4.1087 - val_loss: 4.0458\n","Epoch 3/40\n","14668/14668 [==============================] - 9s 633us/step - loss: 3.9826 - val_loss: 3.9672\n","Epoch 4/40\n","14668/14668 [==============================] - 9s 620us/step - loss: 3.8741 - val_loss: 3.8516\n","Epoch 5/40\n","14668/14668 [==============================] - 9s 589us/step - loss: 3.7796 - val_loss: 3.7563\n","Epoch 6/40\n","14668/14668 [==============================] - 9s 597us/step - loss: 3.7105 - val_loss: 3.7197\n","Epoch 7/40\n","14668/14668 [==============================] - 9s 594us/step - loss: 3.6630 - val_loss: 3.6898\n","Epoch 8/40\n","14668/14668 [==============================] - 9s 610us/step - loss: 3.6322 - val_loss: 3.6685\n","Epoch 9/40\n","14668/14668 [==============================] - 9s 605us/step - loss: 3.6081 - val_loss: 3.6603\n","Epoch 10/40\n","14668/14668 [==============================] - 9s 614us/step - loss: 3.5879 - val_loss: 3.6444\n","Epoch 11/40\n","14668/14668 [==============================] - 9s 610us/step - loss: 3.5696 - val_loss: 3.6338\n","Epoch 12/40\n","14668/14668 [==============================] - 9s 642us/step - loss: 3.5537 - val_loss: 3.6273\n","Epoch 13/40\n","14668/14668 [==============================] - 9s 613us/step - loss: 3.5379 - val_loss: 3.6309\n","Epoch 14/40\n","14668/14668 [==============================] - 9s 598us/step - loss: 3.5214 - val_loss: 3.6237\n","Epoch 15/40\n","14668/14668 [==============================] - 9s 612us/step - loss: 3.5071 - val_loss: 3.6202\n","Epoch 16/40\n","14668/14668 [==============================] - 9s 618us/step - loss: 3.4918 - val_loss: 3.6174\n","Epoch 17/40\n","14668/14668 [==============================] - 9s 616us/step - loss: 3.4782 - val_loss: 3.6309\n","Epoch 18/40\n","14668/14668 [==============================] - 9s 610us/step - loss: 3.4636 - val_loss: 3.6200\n","Epoch 19/40\n","14668/14668 [==============================] - 9s 614us/step - loss: 3.4497 - val_loss: 3.6251\n","Epoch 20/40\n","14668/14668 [==============================] - 9s 599us/step - loss: 3.4361 - val_loss: 3.6318\n","Epoch 21/40\n","14668/14668 [==============================] - 9s 619us/step - loss: 3.4227 - val_loss: 3.6218\n","Epoch 22/40\n","14668/14668 [==============================] - 9s 608us/step - loss: 3.4082 - val_loss: 3.6313\n","Epoch 23/40\n","14668/14668 [==============================] - 9s 604us/step - loss: 3.3952 - val_loss: 3.6356\n","Epoch 24/40\n","14668/14668 [==============================] - 9s 606us/step - loss: 3.3822 - val_loss: 3.6329\n","Epoch 25/40\n","14668/14668 [==============================] - 9s 600us/step - loss: 3.3687 - val_loss: 3.6399\n","Epoch 26/40\n","14668/14668 [==============================] - 9s 608us/step - loss: 3.3561 - val_loss: 3.6384\n","Epoch 27/40\n","14668/14668 [==============================] - 9s 624us/step - loss: 3.3427 - val_loss: 3.6545\n","Epoch 28/40\n","14668/14668 [==============================] - 9s 626us/step - loss: 3.3287 - val_loss: 3.6519\n","Epoch 29/40\n","14668/14668 [==============================] - 9s 638us/step - loss: 3.3164 - val_loss: 3.6522\n","Epoch 30/40\n","14668/14668 [==============================] - 9s 610us/step - loss: 3.3030 - val_loss: 3.6553\n","Epoch 31/40\n","14668/14668 [==============================] - 9s 620us/step - loss: 3.2902 - val_loss: 3.6735\n","Epoch 32/40\n","14668/14668 [==============================] - 9s 621us/step - loss: 3.2784 - val_loss: 3.6660\n","Epoch 33/40\n","14668/14668 [==============================] - 9s 600us/step - loss: 3.2638 - val_loss: 3.6748\n","Epoch 34/40\n","14668/14668 [==============================] - 9s 624us/step - loss: 3.2515 - val_loss: 3.6742\n","Epoch 35/40\n","14668/14668 [==============================] - 9s 618us/step - loss: 3.2395 - val_loss: 3.6866\n","Epoch 36/40\n","14668/14668 [==============================] - 9s 636us/step - loss: 3.2251 - val_loss: 3.6901\n","Epoch 37/40\n","14668/14668 [==============================] - 9s 631us/step - loss: 3.2137 - val_loss: 3.6952\n","Epoch 38/40\n","14668/14668 [==============================] - 9s 627us/step - loss: 3.2024 - val_loss: 3.7020\n","Epoch 39/40\n","14668/14668 [==============================] - 9s 613us/step - loss: 3.1894 - val_loss: 3.7069\n","Epoch 40/40\n","14668/14668 [==============================] - 9s 631us/step - loss: 3.1774 - val_loss: 3.7103\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.callbacks.History at 0x7f3c56103240>"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"markdown","metadata":{"id":"2kdqR70-snQz","colab_type":"text"},"source":["Con la regularización observamos que si bien el loss es más elevado tanto en train como en test, la red puede entrenar durante más epochs sin experimentar un fuerte overfitting. "]},{"cell_type":"code","metadata":{"id":"r-2pgzPfsnQz","colab_type":"code","colab":{}},"source":["save_model(model,'LSTMRegularizado')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AT_IVTZJsnQ1","colab_type":"text"},"source":["### Autoencoders con embeddings\n","\n","Observamos que la regularización no es suficiente para generar buenas representaciones de los datos.\n","Otra posibilidad para implementar autoencoders es agregar una capa de embedding. \n","Recordemos que los embeddings toman un vocabulario y mapean cada ítem de éste a un espacio vectorial de varias dimensiones. De esta manera, los embeddings reconocen distancias multidimensionales entre los elementos del vocabulario que resumen distintas formas de similitud que pueden aprenderse del corpus de entrenamiento.\n","\n","En nuestro caso, los \"documentos\" son cada uno de los chunks de música de Bach y nuestro vocabulario son todas las posibles notas y acordes que figuran en los archivos midi. \n","\n","La función del embedding será tomar este input de 256 dimensiones y mapearlo en un espacio de secuencias.\n","Esto nos permite encontrar en nuestros datos, un equivalete musical de los sinónimos y por lo tanto codificar y decodificar la música con algunas variaciones. \n"]},{"cell_type":"code","metadata":{"id":"QGEqo9QlsnQ1","colab_type":"code","colab":{}},"source":["def get_midi(note_chord_array, file_name):\n","    offset = 0\n","    output_notes = []\n","    # create note and chord objects based on the values generated by the model\n","    for pattern in note_chord_array:\n","        # pattern is a chord\n","        if ('.' in pattern) or pattern.isdigit():\n","            notes_in_chord = pattern.split('.')\n","            notes = []\n","            for current_note in notes_in_chord:\n","                new_note = note.Note(int(current_note))\n","                new_note.storedInstrument = instrument.Piano()\n","                notes.append(new_note)\n","            new_chord = chord.Chord(notes)\n","            new_chord.offset = offset\n","            output_notes.append(new_chord)\n","        # pattern is a note\n","        else:\n","            new_note = note.Note(pattern)\n","            new_note.offset = offset\n","            new_note.storedInstrument = instrument.Piano()\n","            output_notes.append(new_note)\n","        # increase offset each iteration so that notes do not stack\n","        offset += 0.7\n","    midi_stream = stream.Stream(output_notes)\n","    midi_stream.write('midi', fp='{}.mid'.format(file_name))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Th-9ITGOsnQ2","colab_type":"code","colab":{}},"source":["def lstm_embedding_model(sequence_len, input_dim, latent_dim):\n","    # Encoder\n","    inputs = Input(shape=(sequence_len, input_dim))\n","    encoded = Bidirectional(LSTM(latent_dim), merge_mode=\"sum\")(inputs)\n","    # Decoder\n","    decoded = RepeatVector(sequence_len)(encoded)\n","    decoded = Bidirectional(LSTM(input_dim, return_sequences=True), merge_mode=\"sum\")(decoded)\n","    auto_encoder_model = Model(inputs, decoded)\n","    auto_encoder_model.compile(optimizer=\"rmsprop\", loss=\"mse\")\n","    auto_encoder_model.summary()\n","    return auto_encoder_model\n","    #encoder = Model(inputs, encoded)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OkZkJBtYsnQ3","colab_type":"code","colab":{}},"source":["def generate_embedding(all_chunks, embedding_size, embedding_file):\n","    all_chunks = list(map(lambda x: list(x), all_chunks))\n","    word2vec_model = Word2Vec(all_chunks, min_count=1, size=embedding_size)\n","    word2vec_model.save(embedding_file)\n","    return embedding_file"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BE-rL2a6snQ7","colab_type":"code","colab":{}},"source":["def get_embedding(embedding_file):\n","    embedding_model = Word2Vec.load(embedding_file)\n","    print(embedding_model)\n","    return embedding_model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qnhBW6VUsnQ-","colab_type":"code","colab":{}},"source":["def embedding_transform(embedding_model, all_chunks):\n","    return np.array(list(map(lambda chunk: embedding_model.wv[chunk], all_chunks)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6OlONe3qsnRD","colab_type":"code","colab":{}},"source":["def reverse_embedding(predict, embedding_model):\n","    return np.array(list(map(lambda vector: embedding_model.wv.similar_by_vector(vector, topn=1, restrict_vocab=None)[0][0], predict)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0RJ0doPCsnRG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593696007501,"user_tz":180,"elapsed":1173,"user":{"displayName":"Julián Ansaldo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhUb7AsWoOmdCsmzYzXTDr9Sws-IR4J0wcrp266tQ=s64","userId":"10643095115217147090"}},"outputId":"aefad912-1147-498c-9f58-d3b68bac51a5"},"source":["# Utilizamos los arrays originales que contienen chunks de Bach\n","array_input.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(18335, 10)"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"GJwWw--fsnRI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":89},"executionInfo":{"status":"ok","timestamp":1593696008919,"user_tz":180,"elapsed":1906,"user":{"displayName":"Julián Ansaldo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhUb7AsWoOmdCsmzYzXTDr9Sws-IR4J0wcrp266tQ=s64","userId":"10643095115217147090"}},"outputId":"53ffbc3e-25b2-4a35-8a7b-32f4ebd50b1a"},"source":["embedding_size = 50\n","generate_embedding(array_input, embedding_size, 'model.bin')\n","embedding_model = get_embedding('model.bin')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Word2Vec(vocab=256, size=50, alpha=0.025)\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"_g2GLrvGsnRJ","colab_type":"code","colab":{}},"source":["all_chunk_vectors = embedding_transform(embedding_model, array_input)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ygl-2Ss8snRK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593696011107,"user_tz":180,"elapsed":589,"user":{"displayName":"Julián Ansaldo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhUb7AsWoOmdCsmzYzXTDr9Sws-IR4J0wcrp266tQ=s64","userId":"10643095115217147090"}},"outputId":"42fd3b03-fa50-4c57-e303-f1710853775b"},"source":["all_chunk_vectors.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(18335, 10, 50)"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"TIAwJJfKsnRL","colab_type":"code","colab":{}},"source":["x_train, x_test = train_test_split(all_chunk_vectors, random_state=42, test_size = 0.2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c5WAvNNXsnRN","colab_type":"code","colab":{}},"source":["input_dim = embedding_size\n","latent_dim = 25"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OXPnq83gsnRP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":295},"executionInfo":{"status":"ok","timestamp":1593696015245,"user_tz":180,"elapsed":1084,"user":{"displayName":"Julián Ansaldo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhUb7AsWoOmdCsmzYzXTDr9Sws-IR4J0wcrp266tQ=s64","userId":"10643095115217147090"}},"outputId":"1203cd35-b7c0-453d-bd78-dd3b2f1294c9"},"source":["model = lstm_embedding_model(timesteps, input_dim, latent_dim)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model_3\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_3 (InputLayer)         (None, 10, 50)            0         \n","_________________________________________________________________\n","bidirectional_1 (Bidirection (None, 25)                15200     \n","_________________________________________________________________\n","repeat_vector_3 (RepeatVecto (None, 10, 25)            0         \n","_________________________________________________________________\n","bidirectional_2 (Bidirection (None, 10, 50)            30400     \n","=================================================================\n","Total params: 45,600\n","Trainable params: 45,600\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dVK1L1jTsnRR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":801},"executionInfo":{"status":"ok","timestamp":1593696221694,"user_tz":180,"elapsed":206831,"user":{"displayName":"Julián Ansaldo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhUb7AsWoOmdCsmzYzXTDr9Sws-IR4J0wcrp266tQ=s64","userId":"10643095115217147090"}},"outputId":"cf6eb4ef-ff23-4b59-dd5c-08ac3b8c23b2"},"source":["model.fit(x_train, x_train, epochs=20, batch_size=128, shuffle=True, validation_data=(x_test, x_test), callbacks=[TensorBoard(log_dir='/tmp/autoencoder')])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train on 14668 samples, validate on 3667 samples\n","Epoch 1/20\n","  512/14668 [>.............................] - ETA: 1:03 - loss: 0.2216"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.286564). Check your callbacks.\n","  % (hook_name, delta_t_median), RuntimeWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["14668/14668 [==============================] - 12s 816us/step - loss: 0.1319 - val_loss: 0.1166\n","Epoch 2/20\n","14668/14668 [==============================] - 10s 672us/step - loss: 0.1120 - val_loss: 0.1101\n","Epoch 3/20\n","14668/14668 [==============================] - 10s 685us/step - loss: 0.1077 - val_loss: 0.1071\n","Epoch 4/20\n","14668/14668 [==============================] - 10s 698us/step - loss: 0.1060 - val_loss: 0.1061\n","Epoch 5/20\n","14668/14668 [==============================] - 10s 675us/step - loss: 0.1050 - val_loss: 0.1054\n","Epoch 6/20\n","14668/14668 [==============================] - 10s 706us/step - loss: 0.1043 - val_loss: 0.1050\n","Epoch 7/20\n","14668/14668 [==============================] - 10s 678us/step - loss: 0.1038 - val_loss: 0.1042\n","Epoch 8/20\n","14668/14668 [==============================] - 10s 703us/step - loss: 0.1034 - val_loss: 0.1039\n","Epoch 9/20\n","14668/14668 [==============================] - 10s 700us/step - loss: 0.1030 - val_loss: 0.1033\n","Epoch 10/20\n","14668/14668 [==============================] - 10s 689us/step - loss: 0.1025 - val_loss: 0.1030\n","Epoch 11/20\n","14668/14668 [==============================] - 10s 676us/step - loss: 0.1019 - val_loss: 0.1021\n","Epoch 12/20\n","14668/14668 [==============================] - 10s 677us/step - loss: 0.1011 - val_loss: 0.1019\n","Epoch 13/20\n","14668/14668 [==============================] - 10s 716us/step - loss: 0.1004 - val_loss: 0.1003\n","Epoch 14/20\n","14668/14668 [==============================] - 10s 690us/step - loss: 0.0996 - val_loss: 0.0995\n","Epoch 15/20\n","14668/14668 [==============================] - 10s 697us/step - loss: 0.0989 - val_loss: 0.0989\n","Epoch 16/20\n","14668/14668 [==============================] - 10s 676us/step - loss: 0.0982 - val_loss: 0.0984\n","Epoch 17/20\n","14668/14668 [==============================] - 10s 700us/step - loss: 0.0976 - val_loss: 0.0978\n","Epoch 18/20\n","14668/14668 [==============================] - 10s 687us/step - loss: 0.0969 - val_loss: 0.0968\n","Epoch 19/20\n","14668/14668 [==============================] - 10s 669us/step - loss: 0.0962 - val_loss: 0.0963\n","Epoch 20/20\n","14668/14668 [==============================] - 10s 675us/step - loss: 0.0956 - val_loss: 0.0961\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.callbacks.History at 0x7f3bda7019b0>"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"markdown","metadata":{"id":"NAYwECUSsnRS","colab_type":"text"},"source":["Escuchemos ahora uno de los audios originales y el output generado por el modelo."]},{"cell_type":"code","metadata":{"id":"-G8_xhZssnRT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593696268789,"user_tz":180,"elapsed":2268,"user":{"displayName":"Julián Ansaldo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhUb7AsWoOmdCsmzYzXTDr9Sws-IR4J0wcrp266tQ=s64","userId":"10643095115217147090"}},"outputId":"48c0aea0-8efd-44c3-e1f7-1e182a63ee07"},"source":["for i in range(30):\n","    prueba = x_train[i]\n","    muestra = reverse_embedding(prueba, embedding_model)\n","    print(muestra)\n","    get_midi(muestra, 'trainmuestra{}'.format(str(i)))\n","    predict = model.predict(prueba.reshape(1,10,50))[0]\n","    print(predict.shape)\n","    output = reverse_embedding(predict, embedding_model)\n","    print(output)\n","    get_midi(output, 'trainoutput{}'.format(str(i)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n","  if np.issubdtype(vec.dtype, np.int):\n"],"name":"stderr"},{"output_type":"stream","text":["['G#4' 'E3' 'E-4' 'C3' 'E4' 'C#3' 'C#4' 'E3' 'G#3' 'G#3']\n","(10, 50)\n","['G#4' 'G#4' '1.3.6' 'C#3' 'C#3' 'G#3' 'G#3' 'G#3' 'G#3' 'G#3']\n","['D4' 'G3' 'G5' 'D5' 'B-4' 'E-5' 'B-4' 'C4' 'F4' 'C5']\n","(10, 50)\n","['A3' '10.1.5' 'F5' 'F5' 'F5' 'C5' 'B-4' 'B-4' 'B-4' 'B-4']\n","['A4' 'F4' 'E4' 'F4' 'D4' 'C5' 'C4' 'A4' 'F3' 'B-4']\n","(10, 50)\n","['G4' 'G4' 'F4' 'F4' 'F4' 'F4' 'B-1' 'B-4' 'B-4' 'B-4']\n","['F4' 'C#3' 'C#4' 'G3' 'B-3' 'G4' '5.8' 'C4' '4.7' 'B-3']\n","(10, 50)\n","['E-4' 'E-4' 'B-1' 'B-1' 'B-1' '3' '3' '5.7' '5.7' '10.2']\n","['C5' 'E3' 'D3' 'B4' 'C3' 'C5' 'B2' 'D5' 'A2' 'C5']\n","(10, 50)\n","['C5' 'C3' 'D3' 'D3' 'D3' 'C3' 'C3' 'D5' 'D5' 'D5']\n","['3.9' 'G5' 'E4' 'B4' 'G4' 'A5' 'C4' 'F#4' 'D4' 'B5']\n","(10, 50)\n","['4.6.10' 'E-6' 'G6' 'B6' 'B6' 'G4' 'D4' 'D4' 'F6' 'B5']\n","['G3' 'E3' 'B3' 'E-4' 'C3' 'E4' 'G4' 'A2' 'F#4' 'E4']\n","(10, 50)\n","['G3' 'A3' 'A3' 'D4' 'E4' 'E4' 'E4' 'E4' 'E4' 'E4']\n","['F5' 'G5' 'A5' 'B5' 'C6' 'B5' 'C6' 'G4' 'F4' 'G4']\n","(10, 50)\n","['B-5' 'A5' 'A5' 'A5' 'A5' 'E6' 'E6' 'G6' 'G4' 'G4']\n","['B-4' 'F4' 'G#3' 'E-5' 'B-3' 'E-4' 'G3' 'E-4' 'C4' 'D4']\n","(10, 50)\n","['B-4' '10.3' 'B-3' 'B-3' 'B-3' 'B-3' 'B-3' 'C4' 'D4' 'D4']\n","['F#4' 'G2' 'E-3' 'A3' 'C4' 'F#4' 'E-3' 'A3' 'C4' 'F#4']\n","(10, 50)\n","['E4' 'C#2' 'C#2' 'B-1' 'G3' 'A3' 'A3' 'A3' 'E4' 'E4']\n","['G5' 'A5' 'D4' 'F5' 'G5' 'B-3' 'F5' 'E5' 'G3' 'D5']\n","(10, 50)\n","['G5' 'G5' 'G5' 'G5' 'F5' 'F5' 'F5' 'F5' 'D5' 'D5']\n","['G#2' 'G#4' 'A2' 'E-4' 'E4' 'C#4' 'F#4' 'A2' 'C#4' 'E-4']\n","(10, 50)\n","['G#2' 'G#2' 'G#2' 'C#4' 'C#4' 'C#4' 'C#4' 'C#4' 'C#4' 'C#4']\n","['B-4' 'E3' 'C#4' 'B-4' 'G2' 'A4' 'G4' 'C#3' 'F4' 'E4']\n","(10, 50)\n","['B-4' 'B-1' 'B-1' 'B-1' '1.3.6' '1.3.6' '1.3.6' 'G4' 'E4' 'E4']\n","['B4' 'C#5' 'E3' 'F#4' 'C#5' 'D3' 'D5' 'E5' 'C#3' 'F#5']\n","(10, 50)\n","['C#5' 'B4' 'B4' 'C#5' 'C#5' 'C#5' 'F#5' 'F#5' 'F#5' 'F#5']\n","['F#3' 'C5' 'A3' 'D3' 'A5' 'F#3' 'G3' 'B-4' 'D5' 'D3']\n","(10, 50)\n","['G3' 'G3' 'G3' 'G3' 'G3' 'G3' 'G3' 'G3' '5.7.0' '1.4.7.10']\n","['F#3' 'G#3' 'E4' 'E3' 'B3' 'G#3' 'G#3' 'B3' 'A3' 'F#3']\n","(10, 50)\n","['G#3' 'G#3' 'G#3' 'G#3' 'B3' 'B3' 'B3' 'A3' 'A3' 'A3']\n","['B-5' 'D4' 'E-5' 'C4' 'G5' 'E-4' 'F5' 'D4' 'E-5' 'C4']\n","(10, 50)\n","['B-5' 'B-5' 'B-5' '8.10' '10.1.5' 'F5' 'F5' 'F5' 'F5' 'B-3']\n","['A5' 'C5' 'G5' 'B4' 'E3' 'F#5' 'A4' 'C3' 'E5' 'G4']\n","(10, 50)\n","['G5' 'G5' 'G5' 'G5' 'E5' 'E5' 'D5' 'D5' 'D5' 'C5']\n","['F3' 'C5' 'F2' 'A4' 'F5' 'A4' 'F3' 'F4' 'D3' 'B-4']\n","(10, 50)\n","['C2' 'C2' 'C2' 'B-4' 'B-4' 'B-4' 'B-4' 'B-4' 'B-4' 'B-4']\n","['F#4' 'E4' 'D4' 'C#4' 'D4' 'A3' 'D4' 'F#4' 'D4' 'F#4']\n","(10, 50)\n","['E4' 'E4' 'E4' 'E4' 'D4' 'D4' 'E4' 'E4' 'E4' 'F#4']\n","['1.6' 'B-4' '3.6' 'B4' 'C#4' 'E4' 'C#4' 'E3' 'B3' 'B-3']\n","(10, 50)\n","['1.5' '11.1.4' '1.3.6' 'F#4' 'E4' 'C#4' 'C#4' 'B3' 'A3' 'A3']\n","['C#4' 'A2' 'F3' 'G3' 'E3' 'F3' 'A3' 'C#3' 'D3' 'E3']\n","(10, 50)\n","['C#4' 'C#2' 'C#2' 'F3' 'D3' 'D3' 'E3' 'E3' 'E3' 'E3']\n","['E3' 'E5' 'G3' 'E-5' 'F#3' 'E5' 'G3' 'F#4' 'B3' 'G4']\n","(10, 50)\n","['E3' '0.3.5.8' '0.3.5.8' 'D5' 'D5' '0.3.5.8' '1.3.6' 'D4' 'E4' 'E4']\n","['C#5' 'D5' '4' '4.7' 'A4' 'F#5' 'E5' 'F#5' 'E5' '9.1']\n","(10, 50)\n","['D5' 'C#5' 'C#5' '9.11.2.5' 'E5' 'E5' 'F#5' 'F#5' 'F#5' 'F#5']\n","['E-3' 'A3' 'G3' 'D3' 'D4' 'C4' 'B-3' 'G3' 'D4' 'C4']\n","(10, 50)\n","['F3' 'F3' 'G3' 'G3' 'C4' 'C4' 'C4' 'C4' 'C4' 'C4']\n","['G#3' 'G#2' 'G5' 'E-5' 'D5' 'E-5' 'G3' 'G2' 'C5' 'G#3']\n","(10, 50)\n","['G#3' 'E-3' 'E-5' 'E-5' 'E-5' 'D5' 'D5' 'C5' 'B-1' 'A3']\n","['G2' 'A3' 'C4' 'B3' 'A3' 'G3' 'F#3' 'E3' 'B2' 'E-3']\n","(10, 50)\n","['G2' 'C4' 'A3' 'A3' 'A3' 'A3' 'E3' 'E3' 'E3' 'E3']\n","['G4' 'A4' 'A3' 'C5' 'G4' 'A4' 'A3' 'C5' 'G4' 'A4']\n","(10, 50)\n","['G4' 'G4' 'G4' 'G4' 'G4' 'G4' 'A4' 'A4' 'A4' 'A4']\n","['F3' 'G3' 'B4' 'A3' 'A4' 'F3' 'B4' 'A3' 'C5' 'G3']\n","(10, 50)\n","['F3' 'G3' 'G3' 'G3' '1.3.6' '1.3.6' 'C5' 'C5' 'C5' 'G3']\n","['D4' 'B3' 'B3' 'G3' 'F3' 'A4' 'C4' 'B4' 'D4' 'C5']\n","(10, 50)\n","['D4' 'A3' 'A3' 'A3' 'G3' 'G3' '1.3.6' 'G4' 'G4' 'C5']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3dSoVYSCsnRV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":89},"executionInfo":{"status":"ok","timestamp":1593696271144,"user_tz":180,"elapsed":948,"user":{"displayName":"Julián Ansaldo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhUb7AsWoOmdCsmzYzXTDr9Sws-IR4J0wcrp266tQ=s64","userId":"10643095115217147090"}},"outputId":"967933ea-7380-486c-f71c-362b43061aff"},"source":["prueba = x_train[8]\n","muestra = reverse_embedding(prueba, embedding_model)\n","print(muestra)\n","get_midi(muestra, 'tramuestra8')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['B-4' 'F4' 'G#3' 'E-5' 'B-3' 'E-4' 'G3' 'E-4' 'C4' 'D4']\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n","  if np.issubdtype(vec.dtype, np.int):\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"qUSTzUL2snRX","colab_type":"code","colab":{}},"source":["predict = model.predict(prueba.reshape(1,10,50))[0]\n","output = reverse_embedding(predict, embedding_model)\n","print(output)\n","get_midi(output, 'output8')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vF974BQKsnRZ","colab_type":"text"},"source":["Lo interesante de usar un embedding es que podemos generar variaciones sobre el input original que suenan de forma similar pero son diferentes. "]},{"cell_type":"code","metadata":{"id":"YBd69I1KsnRa","colab_type":"code","colab":{}},"source":["posibles_notas = np.unique(array_input)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IhrAgZC_snRd","colab_type":"code","colab":{}},"source":["sequence_to_predict = np.random.choice(posibles_notas, size=10, replace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WQs8A6SlsnRf","colab_type":"text"},"source":["Partiendo de una secuencia aleatorea, generamos una secuencia de musica"]},{"cell_type":"code","metadata":{"id":"lhdQg3RVsnRg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":106},"executionInfo":{"status":"ok","timestamp":1593696301882,"user_tz":180,"elapsed":4735,"user":{"displayName":"Julián Ansaldo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhUb7AsWoOmdCsmzYzXTDr9Sws-IR4J0wcrp266tQ=s64","userId":"10643095115217147090"}},"outputId":"73e67f93-78fb-43f6-978f-7aa4176fba77"},"source":["print('############################')\n","long_sequence = []\n","range_ = 200\n","#sequence_to_predict = list(random_seq)\n","\n","\n","for i in range(range_):\n","    # Utilizo como input el embedding de los ultimos 10 valores de la secuencia\n","    network_input = embedding_transform(embedding_model,[sequence_to_predict])\n","    # Recibimos la transformacion\n","    new_music_embed = model.predict(network_input.reshape(1,10,50))[0]\n","    # Reversa del embedding\n","    new_music = list(reverse_embedding(new_music_embed, embedding_model))\n","    # Me guardo las ultimas notas de la secuencia generada\n","    \n","    long_sequence = long_sequence[:-8] + new_music\n","    # Cambio los dos ultimos valores de sequence_to_predict por un random\n","    sequence_to_predict = new_music\n","    random_song = np.random.choice(range(len(array_input)), size=1, replace=False)[0]\n","    \n","    # Avanzo la secuencia\n","    first_part =  sequence_to_predict[2:10]\n","\n","    #first_part =  list(np.random.choice(posibles_notas, size=5, replace=False))\n","    last_part = list(array_input[random_song][0:2]) \n","    sequence_to_predict = first_part + last_part\n","   \n","print(long_sequence)\n","get_midi(long_sequence[40:], 'GeneradaLSTM2')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["############################\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n","  if np.issubdtype(vec.dtype, np.int):\n"],"name":"stderr"},{"output_type":"stream","text":["['C5', '1.4.7.10', '0.3.5.8', 'G#1', '3.6.9', '3.6.9', 'B-1', 'B-1', 'C2', 'C2', 'C3', 'C3', 'C3', 'G2', 'G2', 'G2', '0.3.5.8', '0.3.5.8', '11.2.5.7', '1.4.8', '1.2', '1.2', 'C#4', '1.2', 'C#2', 'B-1', 'B-4', 'B-4', 'B-4', 'F4', 'F4', 'F4', 'B-1', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'G3', 'G3', 'A3', 'A3', 'A3', 'D4', 'D4', 'D4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'A4', 'B4', 'B4', 'B4', 'B4', 'B4', 'A4', 'A4', 'G4', '1.4.7.10', '3.7.10', 'C#2', 'C#2', 'C#2', '1.2', 'E4', 'E4', 'E4', 'E4', 'B-1', 'B-1', 'D5', 'D5', 'D5', 'A4', 'A4', 'G4', 'G4', 'E4', 'E4', 'E4', 'A1', 'E5', 'E5', 'E5', 'E5', 'E5', 'E5', 'E5', 'E5', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', 'E5', 'F#5', 'F#5', 'F#5', 'F#5', 'F#5', 'F#5', 'F#5', '11.1.4', '11.1.4', 'C#2', 'E2', 'F#2', 'F#2', 'F#2', 'F#2', '1.2', 'B1', 'F#5', 'F#5', 'F#5', 'F#5', 'F#5', '6.9.0.2', 'A3', 'A3', 'B3', 'B3', 'B3', 'B3', 'E4', 'E4', 'E4', 'B-1', 'C3', 'B-2', 'B-2', 'B-2', 'B-2', 'E-2', 'E-2', 'E-2', 'E-2', 'E-2', 'B-2', 'C3', 'C3', 'C3', 'C3', 'D5', 'D5', 'D5', 'D5', 'D5', 'G3', 'G3', 'G3', 'G3', 'G3', 'G3', 'C3', 'C3', 'B-5', 'G5', 'G5', 'G5', 'G5', 'G5', 'G5', 'G5', 'G5', 'G5', 'D5', 'B6', 'F#3', 'F#3', 'F#3', 'F#3', 'F#3', 'F#3', 'F#3', 'F#3', 'F#3', 'F#3', 'F#3', 'F#3', 'B3', 'B3', 'B3', 'B3', 'A3', '9.11.2', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'G5', 'G5', 'G5', 'G5', 'G5', 'G5', 'G5', 'G5', 'G5', 'D5', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'E5', 'E5', 'E5', 'E5', 'E5', 'E5', 'E5', 'E5', 'C#5', 'B1', 'C#4', 'C#4', 'C#4', 'C#4', 'C#4', 'C#4', '1.2', '1.2', 'D2', 'A2', 'A2', 'A2', 'A2', 'F#2', 'F#2', 'F#2', 'F#2', 'C#2', '10.1.5', 'G5', 'G5', 'G5', 'G5', 'G5', 'G5', 'E5', 'E5', 'E5', 'E5', '3.5.9', 'C#2', 'G#2', 'G#2', 'G#2', 'G#2', 'G#2', 'G#2', 'G#2', 'G#2', 'G#2', 'E-2', 'E-2', 'E-2', 'E-2', 'E-2', 'E-2', 'E-2', 'E-2', 'E-2', 'E-2', '1.3.6', '11.1.4', 'A4', 'A4', 'A4', 'A4', 'C5', 'G5', 'G5', 'G5', 'G5', 'G5', 'G5', 'G5', 'G5', '3.6.10', 'E4', 'E4', 'E4', 'E4', '1.3.6', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', '9.11.2', 'E4', 'E4', 'E4', '10.11', '1.4.7.10', 'C#2', 'G#1', 'A1', 'C#2', 'C#2', '1.3.6', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'E3', 'E3', 'F#3', 'F#3', 'F#3', 'F#3', 'A3', 'A3', 'A3', 'G3', 'G3', 'G3', 'G3', 'G3', 'A3', 'A3', 'A3', 'G3', 'G3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'D3', 'G5', 'G5', 'G5', 'G5', 'F5', 'F5', 'F5', '5.7.11', 'A3', 'A3', 'E3', 'E3', 'E3', 'E3', 'G3', 'G3', 'G3', 'G3', 'G3', 'G3', 'G3', 'G3', 'G3', 'D5', 'D5', 'D5', 'D5', 'D5', 'D5', '9.11.2.5', '1.4.8', 'F#4', 'F#4', 'E4', 'E4', 'E4', '8.10', 'B-5', 'F5', 'F5', 'C5', 'C5', 'C3', 'C3', 'C3', 'C3', 'C3', 'C3', 'C3', 'C3', 'G3', 'G3']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OSBsAURisnRi","colab_type":"code","colab":{}},"source":["random_song = np.random.choice(range(len(array_input)), size=1, replace=False)[0]\n","sequence_to_predict = array_input[random_song]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jci8nlDps6k9","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}