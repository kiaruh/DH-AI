{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3.PRACTICA_INDEPENDIENTE_Optimización.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "F2zxL_TtNr5R"
      },
      "source": [
        "# PRÁCTICA INDEPENDIENTE: Optimización\n",
        "\n",
        "En esta práctica independiente, continuamos explorando distintas alternativas de optimización para entrenar un clasificador capaz de etiquetar imágenes correspondientes a las distintas prendas de vestir del dataset [Fashion-MNIST](https://github.com/zalandoresearch/fashion-mnist)\n",
        "\n",
        "![Fashion_MNIST](https://github.com/zalandoresearch/fashion-mnist/blob/master/doc/img/fashion-mnist-sprite.png?raw=true)\n",
        "\n",
        "## Consignas\n",
        "\n",
        "1. Explorar distintas configuraciones de los optimizadores estudiados, variando los argumentos (*learning rate*, *decay*, Nesterov, Beta 1 y Beta 2, etc.).\n",
        "2. Explorar `RMSProp` y `RMSProp` con *momentum* y Nesterov, y probar distintas configuraciones en cada caso.\n",
        "3. En la práctica guiada, hicimos una única prueba para cada optimizador. Ahora bien, si quisiéramos comparar la performance y los tiempos de entrenamiento de cada prueba, una únca corrida no sería suficiente para asegurarnos que un determinado optimizador es mejor que otro, dada la aleatoriedad intrínseca al proceso de aprendizaje de las redes neuronales. Iterar diez veces sobre el entrenamiento de una misma arquitectura de red con cada uno de los siguientes los optimizadores en su versión por defecto: `SGD`, `Adagrad`, `RMSProp`y `Adam`. Volcar los tiempos de entrenamiento y accuracy scores sobre el set de testeo de cada iteración en sendas tablas. Luego, visualizar con [boxplots](https://seaborn.pydata.org/generated/seaborn.boxplot.html) las distintas distribuciones de performance y tiempos de entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wNtmwciRNr5S",
        "colab": {}
      },
      "source": [
        "# Importamos las librerías, módulos y utilidades necesarias\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import keras\n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import fashion_mnist\n",
        "\n",
        "# Cargamos el dataset\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KIX3SRWiNr58",
        "colab": {}
      },
      "source": [
        "# Almacenamos en variables la cantidad de etiquetas objetivo y el tamaño de las imágenes, así como también el input size de nuestros modelos\n",
        "num_labels = len(np.unique(y_train))\n",
        "image_size = x_train.shape[1]\n",
        "input_size = image_size * image_size\n",
        "\n",
        "# Hacemos un reshape de los datos y convertimos a float\n",
        "x_train = x_train.reshape((60000, input_size))\n",
        "x_train = x_train.astype('float64') / 255\n",
        "\n",
        "x_test = x_test.reshape((10000, input_size))\n",
        "x_test = x_test.astype('float64') / 255\n",
        "\n",
        "# Convertimos el vector objetivo a categórico\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dbgGWyY1Nr50",
        "colab": {}
      },
      "source": [
        "from keras import models, layers\n",
        "\n",
        "# Definimos la arquitectura de la red\n",
        "network = models.Sequential()\n",
        "network.add(layers.Dense(256, activation='relu', input_dim=input_size))\n",
        "network.add(layers.Dense(256, activation='relu'))\n",
        "network.add(layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pI0JmMtno1s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importamos el módulo optimizers\n",
        "from keras import optimizers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0KVysuMz_94",
        "colab_type": "text"
      },
      "source": [
        "1. Explorar distintas configuraciones de los optimizadores estudiados, variando los argumentos (*learning rate*, *decay*, Nesterov, Beta 1 y Beta 2, etc.)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVOE_WFftSYV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ds6_ZST0H4h",
        "colab_type": "text"
      },
      "source": [
        "2. Explorar `RMSProp` con *momentum* y Nesterov, y probar distintas configuraciones en cada caso.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuwdoWHPz5j6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHsp12vr0VSn",
        "colab_type": "text"
      },
      "source": [
        "3. En la práctica guiada, hicimos una única prueba para cada optimizador. Ahora bien, si quisiéramos comparar la performance y los tiempos de entrenamiento de cada prueba, una únca corrida no sería suficiente para asegurarnos que un determinado optimizador es mejor que otro, dada la aleatoriedad intrínseca al proceso de aprendizaje de las redes neuronales. Iterar diez veces sobre el entrenamiento de una misma arquitectura de red con cada uno de los siguientes los optimizadores en su versión por defecto: `SGD`, `Adagrad`, `RMSProp`y `Adam`. Volcar los tiempos de entrenamiento y accuracy scores sobre el set de testeo de cada iteración en sendas tablas. Luego, visualizar con [boxplots](https://seaborn.pydata.org/generated/seaborn.boxplot.html) las distintas distribuciones de performance y tiempos de entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DeO9nWDj4Du",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ywua2mX-2_cZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}