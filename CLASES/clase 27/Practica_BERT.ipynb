{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Practica BERT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1xcZxLwqfgu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "89a0d174-f926-486e-8070-0e1f1e33b904"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.11.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers==0.7.0 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.12.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwAyG13xqfQM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets\n",
        "from transformers import *\n",
        "\n",
        "tf.random.set_seed(123)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4u3AeZ37qiOu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e996354e-611b-4777-a97c-2872a081767b"
      },
      "source": [
        "# Levantamos el tokenizador y el modelo para clasificar\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "model = TFBertForSequenceClassification.from_pretrained('bert-base-cased')\n",
        "\n",
        "## y vamos a usar el dataset de mrpc: The Microsoft Research Paraphrase Corpus \n",
        "## son pares de frases en ingles, la tarea consiste en decidir si son semanticamente \n",
        "## equivalentes o no. \n",
        "data = tensorflow_datasets.load('glue/mrpc')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Overwrite dataset info from restored data version.\n",
            "INFO:absl:Reusing dataset glue (/root/tensorflow_datasets/glue/mrpc/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split None, from /root/tensorflow_datasets/glue/mrpc/1.0.0\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ff_dtkjyrQfF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "cdec077d-9417-49b4-a166-7717176b55b5"
      },
      "source": [
        "## veamos un ejemplo: tenemos el indice (idx), la clase (0: no son equivalentes, 1 : son equivalentes)\n",
        "## y las dos frases\n",
        "list(data[\"train\"])[0]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'idx': <tf.Tensor: shape=(), dtype=int32, numpy=1680>,\n",
              " 'label': <tf.Tensor: shape=(), dtype=int64, numpy=0>,\n",
              " 'sentence1': <tf.Tensor: shape=(), dtype=string, numpy=b'The identical rovers will act as robotic geologists , searching for evidence of past water .'>,\n",
              " 'sentence2': <tf.Tensor: shape=(), dtype=string, numpy=b'The rovers act as robotic geologists , moving on six wheels .'>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQAohECrsWK_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Para facilitar todo, transformers trae una funcion para darle formato y convertir cada tarea del glue\n",
        "# a un dataset para tensorflow. Esto facilita mucho comparar modelos, testear ideas y meter modificaciones\n",
        "# sin preocuparse mucho por el preprocesamiento del dataset\n",
        "train_dataset = glue_convert_examples_to_features(data['train'], tokenizer, max_length=128, task='mrpc')\n",
        "valid_dataset = glue_convert_examples_to_features(data['validation'], tokenizer, max_length=128, task='mrpc')\n",
        "train_dataset = train_dataset.batch(32)\n",
        "valid_dataset = valid_dataset.batch(64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4jJSH79sb5f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Nos devuelve un iterable, veamos que tiene adentro:\n",
        "prueba_x, prueba_y = list(train_dataset)[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mack4KTktZn_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "d6202953-f32b-46cd-a5eb-ef837b079627"
      },
      "source": [
        "## una belleza: ya tiene armadas las masks, los inputs tokenizados y pasados a index\n",
        "## y los id de tipo!\n",
        "prueba_x[\"attention_mask\"][0]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(128,), dtype=int32, numpy=\n",
              "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEK55rA-tmud",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## compilamos el modelo\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-05, epsilon=1e-08, clipnorm=1.0)\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHtBv6TkY2Gp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "60af1e5c-f19a-4685-d8a9-4a5783c16417"
      },
      "source": [
        "# Entrenamos y evaluamos\n",
        "history = model.fit(train_dataset, epochs=3, validation_data=valid_dataset)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "115/115 [==============================] - 174s 2s/step - loss: 0.5252 - accuracy: 0.7435 - val_loss: 0.3478 - val_accuracy: 0.8480\n",
            "Epoch 2/3\n",
            "115/115 [==============================] - 171s 1s/step - loss: 0.2636 - accuracy: 0.8912 - val_loss: 0.4009 - val_accuracy: 0.8382\n",
            "Epoch 3/3\n",
            "115/115 [==============================] - 171s 1s/step - loss: 0.0947 - accuracy: 0.9654 - val_loss: 0.4820 - val_accuracy: 0.8578\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrKwRt_Ut9W-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c4f1c661-d9e0-446d-e19c-84064b326239"
      },
      "source": [
        "## Vamos a hacer una pruebita rapida: \n",
        "sentence_0 = \"I like studying every day.\"\n",
        "sentence_1 = \"I enjoy studying every day.\"\n",
        "sentence_2 = \"I never want to study.\"\n",
        "inputs_1 = tokenizer.encode_plus(sentence_0, sentence_1, add_special_tokens=True, return_tensors='tf')\n",
        "inputs_2 = tokenizer.encode_plus(sentence_0, sentence_2, add_special_tokens=True, return_tensors='tf')\n",
        "\n",
        "\n",
        "pred_1 = model(inputs_1)[0].numpy().argmax(1)[0]\n",
        "pred_2 = model(inputs_2)[0].numpy().argmax(1)[0]\n",
        "\n",
        "print(\"sentence_1 is\", \"a paraphrase\" if pred_1 else \"not a paraphrase\", \"of sentence_0\")\n",
        "print(\"sentence_2 is\", \"a paraphrase\" if pred_2 else \"not a paraphrase\", \"of sentence_0\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sentence_1 is a paraphrase of sentence_0\n",
            "sentence_2 is not a paraphrase of sentence_0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}