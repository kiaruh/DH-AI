{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seq2Seq",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3p6mqWaJoJ4",
        "colab_type": "code",
        "outputId": "cb14a3df-7967-4dae-f571-0237642adee8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import unicodedata\n",
        "import re\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import io\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import unicodedata\n",
        "import urllib3\n",
        "import shutil\n",
        "import zipfile\n",
        "import itertools\n",
        "\n",
        "\n",
        "from keras.layers import Embedding, LSTM, Dense, Activation, Dot, concatenate, TimeDistributed\n",
        "\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras import preprocessing\n",
        "\n",
        "tf.random.set_seed(1234)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoxrFyDbbqL9",
        "colab_type": "text"
      },
      "source": [
        "Vamos a armar un traductor del ingles al español usando un modelo seq2seq con atencion. Para eso primero necesitamos pares de frases en inglés y español"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gewcRxEtKHpi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!wget http://www.manythings.org/anki/spa-eng.zip\n",
        "#!unzip spa-eng.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9nkeso3Gy6Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(\"./spa.txt\", sep = \"\\t\",header=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9i3HoHcnMCwx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "esp_data_raw = df.iloc[:,1].tolist()\n",
        "eng_data_raw = df.iloc[:,0].tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5fVXTHAKOE0C",
        "colab": {}
      },
      "source": [
        "## defino funciones de limpieza\n",
        "def unicode_to_ascii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn')\n",
        "    \n",
        "def normalize_string(s):\n",
        "    s = unicode_to_ascii(s)\n",
        "    s = re.sub(r'([!.?])', r' \\1', s)\n",
        "    s = re.sub(r'[^a-zA-Z.!?]+', r' ', s)\n",
        "    s = re.sub(r'\\s+', r' ', s)\n",
        "    return s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gOko5xqHOE0W",
        "colab": {}
      },
      "source": [
        "## tengo la data limpia y le agrego tokens de inicio y de fin\n",
        "raw_data_en = [normalize_string(data) for data in eng_data_raw]\n",
        "raw_data_es_in = ['<start> ' + normalize_string(data) +\" <end>\" for data in esp_data_raw]\n",
        "raw_data_es_out = [normalize_string(data) +\" <end>\" for data in esp_data_raw]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LRACxe1tOE0d",
        "colab": {}
      },
      "source": [
        "## defino el largo maximo de la frase\n",
        "max_length = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tSJkNdShOE0g",
        "colab": {}
      },
      "source": [
        "## instancio el tokenizador para ingles. Tokenizo y hago padding\n",
        "en_tokenizer = preprocessing.text.Tokenizer(filters=\"\")\n",
        "en_tokenizer.fit_on_texts(raw_data_en)\n",
        "data_en = en_tokenizer.texts_to_sequences(raw_data_en)\n",
        "data_en = preprocessing.sequence.pad_sequences(data_en, padding='post',maxlen= max_length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NTRhhRJZOE0k",
        "colab": {}
      },
      "source": [
        "## repito en español. Voy a tener uno para el input y uno para\n",
        "## usar en el teacher forcing\n",
        "\n",
        "es_tokenizer = preprocessing.text.Tokenizer(filters='')\n",
        "es_tokenizer.fit_on_texts(raw_data_es_in)\n",
        "es_tokenizer.fit_on_texts(raw_data_es_out)\n",
        "\n",
        "data_es_in = es_tokenizer.texts_to_sequences(raw_data_es_in)\n",
        "data_es_in = preprocessing.sequence.pad_sequences(data_es_in, padding='post',maxlen= max_length)\n",
        "\n",
        "data_es_out = es_tokenizer.texts_to_sequences(raw_data_es_out)\n",
        "data_es_out = preprocessing.sequence.pad_sequences(data_es_out, padding='post',maxlen= max_length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-zI4o1bxOE0m",
        "colab": {}
      },
      "source": [
        "## defino el tamaño del vocabulario (le sumo 1 por el 0 del padding)\n",
        "max_words_es = len(es_tokenizer.index_word.keys())+1\n",
        "max_words_en = len(en_tokenizer.index_word.keys())+1\n",
        "\n",
        "## y algunas caracteristicas de la red\n",
        "embedding_dim= 1024\n",
        "lstm_size = 1024\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "fc2bb094-f87a-425a-cc9d-fe736f8e3a4d",
        "id": "oOybppIRjV7x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "## voy a usar una sola capa de lstm con dropout. En el paper de luong usan un\n",
        "## stack de 4. Pero ellos tenian aprox 4 millones de frases y entrenaban 7 dias\n",
        "\n",
        "encoder_input = keras.Input(shape=(max_length,))\n",
        "decoder_input = keras.Input(shape=(max_length,))\n",
        "\n",
        "encoder_embedding = Embedding(max_words_en, embedding_dim, input_length = max_length,mask_zero=True)\n",
        "encoder = LSTM(lstm_size, return_state=True,return_sequences = True, dropout=0.2)\n",
        "decoder_embedding = Embedding(max_words_es, embedding_dim, input_length = max_length,mask_zero=True)\n",
        "decoder = LSTM(lstm_size,return_sequences=True, return_state=True,dropout=0.2)\n",
        "\n",
        "e_embedding = encoder_embedding(encoder_input)\n",
        "encoder_out,state_h,state_c = encoder(e_embedding)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "d_embedding = decoder_embedding(decoder_input)\n",
        "decoder_out,_,_ = decoder(d_embedding, initial_state=encoder_states)\n",
        "\n",
        "## si no quiero usar atencion puedo cortar acá y enchufar ya la salida:\n",
        "#output = TimeDistributed(Dense(max_words_es, activation=\"softmax\"))(decoder_out)\n",
        "\n",
        "\n",
        "attention = Dot(axes=(2, 2))([decoder_out, encoder_out])\n",
        "attention = Activation('softmax', name='attention')(attention)\n",
        "print('attention', attention)\n",
        "\n",
        " \n",
        "context = Dot(axes=(2,1))([attention, encoder_out])\n",
        "print('context', context)\n",
        "\n",
        "decoder_mas_context = concatenate([context, decoder_out])\n",
        "print('decoder_combined_context', decoder_mas_context)\n",
        "\n",
        "output = TimeDistributed(Dense(64, activation=\"tanh\"))(decoder_mas_context)\n",
        "output = TimeDistributed(Dense(max_words_es, activation=\"softmax\"))(output)\n",
        "print('output', output)\n",
        "\n",
        "\n",
        "model = keras.Model(inputs=[encoder_input,decoder_input], outputs=output)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "attention Tensor(\"attention/truediv:0\", shape=(None, 50, 50), dtype=float32)\n",
            "context Tensor(\"dot_2/MatMul:0\", shape=(None, 50, 1024), dtype=float32)\n",
            "decoder_combined_context Tensor(\"concatenate_1/concat:0\", shape=(None, 50, 2048), dtype=float32)\n",
            "output Tensor(\"time_distributed_2/Reshape_1:0\", shape=(None, 50, 25238), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNi05_VUn9FH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "adam = tf.keras.optimizers.Adam(\n",
        "    learning_rate=0.001,\n",
        "    beta_1=0.9,\n",
        "    beta_2=0.999,\n",
        "    epsilon=1e-07,\n",
        "    amsgrad=False,\n",
        "    name=\"Adam\",\n",
        "    clipnorm = 5\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c9ba2cc4-327a-419e-e822-8e4403ad1b19",
        "id": "Nqu76HuDjV77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "model.compile(optimizer = adam, loss=\"sparse_categorical_crossentropy\")\n",
        "history = model.fit([data_en,data_es_in], np.expand_dims(data_es_out,2), batch_size=128, epochs=10, validation_split=.2, shuffle = True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 99016 samples, validate on 24754 samples\n",
            "Epoch 1/10\n",
            "99016/99016 [==============================] - 857s 9ms/step - loss: 0.8387 - val_loss: 1.3560\n",
            "Epoch 2/10\n",
            "99016/99016 [==============================] - 856s 9ms/step - loss: 0.6208 - val_loss: 1.0911\n",
            "Epoch 3/10\n",
            "99016/99016 [==============================] - 855s 9ms/step - loss: 0.4502 - val_loss: 0.8905\n",
            "Epoch 4/10\n",
            "99016/99016 [==============================] - 852s 9ms/step - loss: 0.3392 - val_loss: 0.7663\n",
            "Epoch 5/10\n",
            "99016/99016 [==============================] - 855s 9ms/step - loss: 0.2634 - val_loss: 0.6957\n",
            "Epoch 6/10\n",
            "99016/99016 [==============================] - 853s 9ms/step - loss: 0.2129 - val_loss: 0.6576\n",
            "Epoch 7/10\n",
            "99016/99016 [==============================] - 855s 9ms/step - loss: 0.1771 - val_loss: 0.6400\n",
            "Epoch 8/10\n",
            "99016/99016 [==============================] - 852s 9ms/step - loss: 0.1504 - val_loss: 0.6371\n",
            "Epoch 9/10\n",
            "99016/99016 [==============================] - 852s 9ms/step - loss: 0.1294 - val_loss: 0.6300\n",
            "Epoch 10/10\n",
            "99016/99016 [==============================] - 853s 9ms/step - loss: 0.1124 - val_loss: 0.6372\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ql6aliCIDh6G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## me armo una funcion para traducir usando el modelo.\n",
        "def traducir(frase,palabras=False):\n",
        "  infer_deco_input = np.zeros(max_length)\n",
        "  infer_deco_input[0] = es_tokenizer.word_index[\"<start>\"]\n",
        "  pos =0\n",
        "  en_input = frase.reshape(1,-1)\n",
        "  es_input= infer_deco_input.reshape(1,-1)\n",
        "  while pos <= max_length:\n",
        "    pred= model.predict([en_input,es_input]).argmax(2)\n",
        "    es_input[0,pos+1] = pred[0][pos]\n",
        "    if pred[0][pos] in (0,1):\n",
        "      break\n",
        "    pos +=1\n",
        "  traduccion = es_input\n",
        "\n",
        "  if palabras:\n",
        "    texto= \" \".join([es_tokenizer.index_word[x] for x in traduccion[0] if x !=0])\n",
        "    return traduccion,texto\n",
        "\n",
        "  return traduccion"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7uhwjemFQ_p",
        "colab_type": "code",
        "outputId": "a2b5820d-10aa-4662-f0a3-4edb525990bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "## si falla entrenar 2 mas\n",
        "\"i need chocolate\" in eng_data_raw"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZEW604KcRDd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "frase_a_traducir = \"i need chocolate\"\n",
        "prueba_predict_en = [en_tokenizer.word_index[x] for x in frase_a_traducir.split()]\n",
        "prueba_predict_en = preprocessing.sequence.pad_sequences([prueba_predict_en], padding='post',maxlen= max_length)[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeIEUISVYE3u",
        "colab_type": "code",
        "outputId": "e45e438e-9f9b-4902-cc3a-8c8c4c8e8ba7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\" \".join([en_tokenizer.index_word[x] for x in prueba_predict_en if x!= 0]))\n",
        "print(traducir(prueba_predict_en,True)[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i need chocolate\n",
            "<start> necesito chocolate . <end>\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}